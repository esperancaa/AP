{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### web scraping (só pelo o id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Blast import NCBIXML \n",
    "from Bio.Blast import NCBIWWW\n",
    "import requests, sys, json\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from Bio import SearchIO\n",
    "from Bio.SwissProt import KeyWList\n",
    "from Bio import SwissProt\n",
    "from Bio import ExPASy\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from Bio.Seq import Seq\n",
    "from Bio import AlignIO\n",
    "from Bio.Align import AlignInfo\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from Bio.Phylo.TreeConstruction import DistanceCalculator\n",
    "from Bio.Phylo.TreeConstruction import DistanceTreeConstructor\n",
    "from Bio import Phylo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ncbi.nlm.nih.gov/nuccore/NG_009243',\n",
       " 'https://www.ncbi.nlm.nih.gov/nuccore/NG_009244',\n",
       " 'https://www.ncbi.nlm.nih.gov/nuccore/NG_009245',\n",
       " 'https://www.ncbi.nlm.nih.gov/nuccore/NG_009246']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "def url_get(i):\n",
    "    url_list= [ ]\n",
    "    for id in range(243,(243+i)):\n",
    "        url = \"https://www.ncbi.nlm.nih.gov/nuccore/NG_009{}\".format( id )\n",
    "        url_list.append(url)\n",
    "    return url_list\n",
    "url_get(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "content = []\n",
    "for url in url_get(4):\n",
    "    r = requests.get(url)\n",
    "    content.append(r.content)\n",
    "#print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<meta content=\"325910839\" name=\"ncbi_uidlist\"/>\n",
      "ncbi_uidlist\n",
      "325910839\n",
      "<meta content=\"1543376889\" name=\"ncbi_uidlist\"/>\n",
      "ncbi_uidlist\n",
      "1543376889\n",
      "<meta content=\"219521908\" name=\"ncbi_uidlist\"/>\n",
      "ncbi_uidlist\n",
      "219521908\n",
      "<meta content=\"219521909\" name=\"ncbi_uidlist\"/>\n",
      "ncbi_uidlist\n",
      "219521909\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Parsing the HTML\n",
    "for c in content:\n",
    "    soup = BeautifulSoup(c, 'html.parser')\n",
    "\n",
    "    # Procurar um tag meta com um determinado atributo\n",
    "    lines = soup.find_all('meta', {'name':\"ncbi_uidlist\"} )\n",
    "\n",
    "    id = \"\"\n",
    "    url = \"\"\n",
    "    for line in lines:\n",
    "        print(line)\n",
    "        if 'name' in line.attrs:\n",
    "            print(line.attrs['name'])\n",
    "        if 'content' in line.attrs:\n",
    "            print(line.attrs['content'])\t\t\n",
    "            id = line.attrs['content']\n",
    "    if id:\n",
    "        url = \"https://www.ncbi.nlm.nih.gov/sviewer/viewer.fcgi?id={}&db=nuccore&report=genbank&conwithfeat=on&hide-cdd=on&retmode=text&maxdownloadsize=5000000\".format(id)\n",
    "\n",
    "    r2 = requests.get( url )\n",
    "    r3= r2.content.decode('utf-8')\n",
    "    #r3= str(r2.content)\n",
    "    #print (r3, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import re\n",
    "#existe = re.findall(r\"ORGANISM\\s+.*?(?=bp)\", r3, re.DOTALL)\n",
    "#if existe:\n",
    "    #for definition in existe:\n",
    "        #m = re.match( r\"ORGANISM\\s+(.+)\", definition, re.DOTALL )\n",
    "        #print( re.sub(r'\\s+', ' ', m.group(1) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### web scraping (por condição)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escolha o que quer pesquisar: irs1\n",
      "escolha o nº de genes que quer obter (máximo 20): 10\n",
      "['3667', '3667', '16367', '25467', '559281', '3077574', '100512686', '538598', '459985', '100607873']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "query= input('escolha o que quer pesquisar: ')\n",
    "def url_get(i):\n",
    "    url_list= [ ]\n",
    "    url = \"https://www.ncbi.nlm.nih.gov/gene/?term={}\".format( query )\n",
    "    url_list.append(url)\n",
    "    return url_list\n",
    "url_get(1)\n",
    "\n",
    "import requests, sys, json\n",
    "content = []\n",
    "for url in url_get(1):\n",
    "    r = requests.get(url)\n",
    "    content.append(r.content)\n",
    "#print(content)\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Parsing the HTML\n",
    "for c in content:\n",
    "    soup = BeautifulSoup(c, 'html.parser')\n",
    "    a= soup.get_text()\n",
    "    #print (a)\n",
    "\n",
    "import re\n",
    "existe = re.findall(r\"ID:\\s+\\d*(?=\\D)\", a, re.DOTALL)\n",
    "\n",
    "c= ', '.join(existe)\n",
    "h= c.replace('ID: ','')\n",
    "IDS= h.split(', ')\n",
    "\n",
    "n_genes= IDS[0:int(input('escolha o nº de genes que quer obter (máximo 20): '))]\n",
    "#print(n_genes)\n",
    "\n",
    "if n_genes == ['']:\n",
    "    print (\"Não encontramos resultado para a sua pesquisa\")\n",
    "else:\n",
    "    print (n_genes)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar Links dos genes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ncbi.nlm.nih.gov/nuccore/3667',\n",
       " 'https://www.ncbi.nlm.nih.gov/nuccore/3667',\n",
       " 'https://www.ncbi.nlm.nih.gov/nuccore/16367',\n",
       " 'https://www.ncbi.nlm.nih.gov/nuccore/25467',\n",
       " 'https://www.ncbi.nlm.nih.gov/nuccore/559281',\n",
       " 'https://www.ncbi.nlm.nih.gov/nuccore/3077574',\n",
       " 'https://www.ncbi.nlm.nih.gov/nuccore/100512686',\n",
       " 'https://www.ncbi.nlm.nih.gov/nuccore/538598',\n",
       " 'https://www.ncbi.nlm.nih.gov/nuccore/459985',\n",
       " 'https://www.ncbi.nlm.nih.gov/nuccore/100607873']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "def url_get_id(i):\n",
    "    url_list= [ ]\n",
    "    for id in n_genes:\n",
    "        url = \"https://www.ncbi.nlm.nih.gov/nuccore/{}\".format( id )\n",
    "        url_list.append(url)\n",
    "    return url_list\n",
    "url_get_id(n_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "content_id = []\n",
    "for url in url_get_id(n_genes):\n",
    "    r = requests.get(url)\n",
    "    content_id.append(r.content)\n",
    "#print(content_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<meta content=\"3667\" name=\"ncbi_uidlist\"/>\n",
      "ncbi_uidlist\n",
      "3667\n",
      "<meta content=\"3667\" name=\"ncbi_uidlist\"/>\n",
      "ncbi_uidlist\n",
      "3667\n",
      "<meta content=\"16367\" name=\"ncbi_uidlist\"/>\n",
      "ncbi_uidlist\n",
      "16367\n",
      "<meta content=\"25467\" name=\"ncbi_uidlist\"/>\n",
      "ncbi_uidlist\n",
      "25467\n",
      "<meta content=\"559281\" name=\"ncbi_uidlist\"/>\n",
      "ncbi_uidlist\n",
      "559281\n",
      "<meta content=\"3077574\" name=\"ncbi_uidlist\"/>\n",
      "ncbi_uidlist\n",
      "3077574\n",
      "<meta content=\"100512686\" name=\"ncbi_uidlist\"/>\n",
      "ncbi_uidlist\n",
      "100512686\n",
      "<meta content=\"538598\" name=\"ncbi_uidlist\"/>\n",
      "ncbi_uidlist\n",
      "538598\n",
      "<meta content=\"459985\" name=\"ncbi_uidlist\"/>\n",
      "ncbi_uidlist\n",
      "459985\n",
      "<meta content=\"100607873\" name=\"ncbi_uidlist\"/>\n",
      "ncbi_uidlist\n",
      "100607873\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Parsing the HTML\n",
    "for c in content_id:\n",
    "    soup_id = BeautifulSoup(c, 'html.parser')\n",
    "\n",
    "    # Procurar um tag meta com um determinado atributo\n",
    "    lines_id = soup_id.find_all('meta', {'name':\"ncbi_uidlist\"} )\n",
    "\n",
    "    id_id = \"\"\n",
    "    url_id = \"\"\n",
    "    for line in lines_id:\n",
    "        print(line)\n",
    "        if 'name' in line.attrs:\n",
    "            print(line.attrs['name'])\n",
    "        if 'content' in line.attrs:\n",
    "            print(line.attrs['content'])\t\t\n",
    "            id_id = line.attrs['content']\n",
    "    if id:\n",
    "        url_id = \"https://www.ncbi.nlm.nih.gov/sviewer/viewer.fcgi?id={}&db=nuccore&report=genbank&conwithfeat=on&hide-cdd=on&retmode=text&maxdownloadsize=5000000\".format(id_id)\n",
    "\n",
    "    r2 = requests.get(url_id)\n",
    "    r4= r2.content.decode('utf-8')\n",
    "    #print (r4, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X03907.1\n",
      "AA928418.1\n",
      "AAADR0035516.1\n",
      "L20655.1\n",
      "AAADU0045050.1\n"
     ]
    }
   ],
   "source": [
    "Ids=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    Ids.append(info.id)\n",
    "    print(info.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar quantidade de cds e a sua localização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ids=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "featcds = [ ]\n",
    "position=0\n",
    "pos=[]\n",
    "for info in records:\n",
    "    #print(info.id)\n",
    "    for i in range(len(info.features)):\n",
    "        if info.features[i].type == \"CDS\":\n",
    "            featcds.append(i)\n",
    "            cds= i\n",
    "            a= str(cds)\n",
    "            print (len(a))\n",
    "            position=i\n",
    "            pos.append(info.features[position].location)\n",
    "            print (pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar Ids de proteinas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CAA27540.1', 'AAA47844.1']\n"
     ]
    }
   ],
   "source": [
    "list_pro=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    for i in info.features:\n",
    "        if i.type == \"CDS\":\n",
    "            \n",
    "            pro= str(i.qualifiers[\"protein_id\"])\n",
    "            list_pro.append(pro)\n",
    "div= ', '.join(list_pro)\n",
    "h= div.replace(\"['\",'')\n",
    "hh= h.replace(\"']\",'')\n",
    "ID_PROT= hh.split(', ')\n",
    "print (ID_PROT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar Links de proteinas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "ID_PROT\n",
    "def url_get_id_p(a):\n",
    "    url_list_p=[ ]\n",
    "    for id_p in ID_PROT:\n",
    "        url_id_p= \"https://www.uniprot.org/uniprotkb?query={}\".format(id_p)\n",
    "        url_list_p.append(url_id_p)\n",
    "    return url_list_p\n",
    "url_ids_protein=url_get_id_p(ID_PROT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(url, **kwargs):\n",
    "    response = requests.get(url, **kwargs);\n",
    "\n",
    "    if not response.ok:\n",
    "        print(response.text)\n",
    "        response.raise_for_status()\n",
    "        sys.exit()\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Entry\\nP0CJ48\\n'\n",
      "b'Entry\\nQ88364\\n'\n"
     ]
    }
   ],
   "source": [
    "# if the output is empty, it means that the protein is not reviewed \n",
    "fields=\"accession\"\n",
    "WEBSITE_API=\"https://rest.uniprot.org\"\n",
    "accession=[]\n",
    "\n",
    "for i in ID_PROT:\n",
    "    r=get_url(\"{}/uniprotkb/search?query={} AND (reviewed:true)&fields={}&size=1&format=tsv\".format(WEBSITE_API,i,fields))\n",
    "    accession.append(str(r.content))\n",
    "   \n",
    "for x in accession:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Subcellular location [CC]\\nSUBCELLULAR LOCATION: Plastid, chloroplast thylakoid membrane; Multi-pass membrane protein.\\n'\n",
      "b'Subcellular location [CC]\\n\\n'\n"
     ]
    }
   ],
   "source": [
    "fields=\"cc_subcellular_location\"\n",
    "WEBSITE_API=\"https://rest.uniprot.org\"\n",
    "sub_location=[]\n",
    "\n",
    "for i in ID_PROT:\n",
    "    r=get_url(\"{}/uniprotkb/search?query={} AND (reviewed:true)&fields={}&size=1&format=tsv\".format(WEBSITE_API,i,fields))\n",
    "    sub_location.append(str(r.content))\n",
    "   \n",
    "for x in sub_location:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"accession,organism_name,protein_name,cc_subcellular_location,cc_function\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for accession\n",
      "b'Entry\\nP0CJ48\\n'\n",
      "b'Entry\\n'\n",
      "Results for organism_name\n",
      "b'Organism\\nArabidopsis thaliana (Mouse-ear cress)\\n'\n",
      "b'Organism\\n'\n",
      "Results for protein_name\n",
      "b'Protein names\\nChlorophyll a-b binding protein 2, chloroplastic (Chlorophyll a-b protein 165) (CAB-165) (LHCII type I CAB-2)\\n'\n",
      "b'Protein names\\n'\n",
      "Results for cc_subcellular_location\n",
      "b'Subcellular location [CC]\\nSUBCELLULAR LOCATION: Plastid, chloroplast thylakoid membrane; Multi-pass membrane protein.\\n'\n",
      "b'Subcellular location [CC]\\n'\n",
      "Results for cc_function\n",
      "b'Function [CC]\\nFUNCTION: The light-harvesting complex (LHC) functions as a light receptor, it captures and delivers excitation energy to photosystems with which it is closely associated.\\n'\n",
      "b'Function [CC]\\n'\n"
     ]
    }
   ],
   "source": [
    "WEBSITE_API = \"https://rest.uniprot.org\"\n",
    "fields = [\"accession\",\"organism_name\",\"protein_name\",\"cc_subcellular_location\",\"cc_function\"]\n",
    "\n",
    "def get_field_for_id(ID_PROT, field):\n",
    "    response = get_url(\"{}/uniprotkb/search?query={} AND (reviewed:true)&fields={}&size=1&format=tsv\".format(WEBSITE_API,ID_PROT,field))\n",
    "    return str(response.content)\n",
    "\n",
    "\n",
    "result = {}\n",
    "for field in fields:\n",
    "    result[field] = [get_field_for_id(i, field) for i in ID_PROT]\n",
    "\n",
    "for field, values in result.items():\n",
    "    print(f\"Results for {field}\")\n",
    "    for x in values:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for a in ID_PROT:\n",
    "#     with ExPASy.get_sprot_raw(a) as handle:\n",
    "#             seq_record = SeqIO.read(handle, \"nt\")\n",
    "#             print(seq_record.id)\n",
    "#             print(seq_record.seq)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "content_id_p = []\n",
    "for url in url_get_id_p(len(ID_PROT)):\n",
    "    rp = requests.get(url)\n",
    "    content_id_p.append(rp.content)\n",
    "#print(content_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingSchema",
     "evalue": "Invalid URL '': No scheme supplied. Perhaps you meant http://?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMissingSchema\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m id_id_p:\n\u001b[1;32m     21\u001b[0m     url_id_p \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://rest.uniprot.org/uniprotkb/search?query=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m AND (reviewed:true)&fields=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m&size=1&format=tsv\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(id_id_p)\n\u001b[0;32m---> 23\u001b[0m r7 \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_id_p\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m r8\u001b[38;5;241m=\u001b[39m r7\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m (r8, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/api.py:75\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:515\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;66;03m# Create the Request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m req \u001b[38;5;241m=\u001b[39m Request(\n\u001b[1;32m    504\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod\u001b[38;5;241m.\u001b[39mupper(),\n\u001b[1;32m    505\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m     hooks\u001b[38;5;241m=\u001b[39mhooks,\n\u001b[1;32m    514\u001b[0m )\n\u001b[0;32m--> 515\u001b[0m prep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    517\u001b[0m proxies \u001b[38;5;241m=\u001b[39m proxies \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    519\u001b[0m settings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerge_environment_settings(\n\u001b[1;32m    520\u001b[0m     prep\u001b[38;5;241m.\u001b[39murl, proxies, stream, verify, cert\n\u001b[1;32m    521\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:443\u001b[0m, in \u001b[0;36mSession.prepare_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    440\u001b[0m     auth \u001b[38;5;241m=\u001b[39m get_netrc_auth(request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    442\u001b[0m p \u001b[38;5;241m=\u001b[39m PreparedRequest()\n\u001b[0;32m--> 443\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCaseInsensitiveDict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_setting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcookies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerged_cookies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmerge_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhooks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/models.py:318\u001b[0m, in \u001b[0;36mPreparedRequest.prepare\u001b[0;34m(self, method, url, headers, files, data, params, auth, cookies, hooks, json)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;124;03m\"\"\"Prepares the entire request with the given parameters.\"\"\"\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_method(method)\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_headers(headers)\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_cookies(cookies)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/models.py:392\u001b[0m, in \u001b[0;36mPreparedRequest.prepare_url\u001b[0;34m(self, url, params)\u001b[0m\n\u001b[1;32m    389\u001b[0m     error \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: No scheme supplied. Perhaps you meant http://\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    390\u001b[0m     error \u001b[38;5;241m=\u001b[39m error\u001b[38;5;241m.\u001b[39mformat(to_native_string(url, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m--> 392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MissingSchema(error)\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m host:\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidURL(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid URL \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m: No host supplied\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m url)\n",
      "\u001b[0;31mMissingSchema\u001b[0m: Invalid URL '': No scheme supplied. Perhaps you meant http://?"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Parsing the HTML\n",
    "for c in content_id_p:\n",
    "    soup_id_p = BeautifulSoup(c, 'html.parser')\n",
    "\n",
    "    # Procurar um tag meta com um determinado atributo\n",
    "    lines_id_p = soup_id_p.find_all('meta', {'name':\"id\"} )\n",
    "\n",
    "    id_id_p= \"\"\n",
    "    url_id_p = \"\"\n",
    "    for line in lines_id_p:\n",
    "        print(line)\n",
    "        if 'name' in line.attrs:\n",
    "            print(line.attrs['name'])\n",
    "        if 'content' in line.attrs:\n",
    "            print(line.attrs['content'])\t\t\n",
    "            id_id_p = line.attrs['content']\n",
    "    if id_id_p:\n",
    "        url_id_p = \"https://rest.uniprot.org/uniprotkb/search?query={} AND (reviewed:true)&fields='id'&size=1&format=tsv\".format(id_id_p)\n",
    "\n",
    "    r7 = requests.get(url_id_p)\n",
    "    r8= r7.content.decode('utf-8')\n",
    "    print (r8, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar seq:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Biopython\n",
    "Ids=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "seq=[]\n",
    "for info in records:\n",
    "    print(info.id)\n",
    "    print(info.seq[0:50],'...',info.seq[-10:])\n",
    "    print()\n",
    "    seq.append(f'{info.seq[0:50]}...{info.seq[-10:]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar gene description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ids=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "description=[]\n",
    "for info in records:\n",
    "    print(info.id)\n",
    "    print(info.description)\n",
    "    description.append(info.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar artigos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ids=[]\n",
    "database = 'PubMed'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"medline\", retmode=\"text\") \n",
    "records = Medline.parse(handle)\n",
    "description=[]\n",
    "for info in records:\n",
    "    print(\"title:\", info.get(\"TI\", \"-\"))\n",
    "    print('authors: ', info.get(\"AU\", \"-\"))\n",
    "    print(\"source:\", info.get(\"SO\", \"-\"))\n",
    "    print(\"affiliation: \", info.get(\"AD\", \"-\") ) # FAZER O IF/ELSE PARA O CASO DE NÃO TER AFFILIATION\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Jorge Gustavo Rocha"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
