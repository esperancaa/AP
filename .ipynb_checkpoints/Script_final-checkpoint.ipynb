{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "022bf988",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    "import re\n",
    "from Bio import SeqIO\n",
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from Bio import SearchIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "import mysql.connector as SQLC\n",
    "import mysql.connector\n",
    "from datetime import date\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from Bio.SeqFeature import CompoundLocation\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e05384b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escolha o que quer pesquisar: irs1\n",
      "escolha o nº de genes que quer obter (máximo 20): 20\n",
      "['https://www.ncbi.nlm.nih.gov/nuccore/X03907.1', 'https://www.ncbi.nlm.nih.gov/nuccore/AA928418.1', 'https://www.ncbi.nlm.nih.gov/nuccore/AAADR0035516.1', 'https://www.ncbi.nlm.nih.gov/nuccore/L20655.1', 'https://www.ncbi.nlm.nih.gov/nuccore/AAADU0045050.1', 'https://www.ncbi.nlm.nih.gov/nuccore/AAAEJ0028203.1', 'https://www.ncbi.nlm.nih.gov/nuccore/AAAEJ0013167.1', 'https://www.ncbi.nlm.nih.gov/nuccore/F00426.1', 'https://www.ncbi.nlm.nih.gov/nuccore/AA628858.1', 'https://www.ncbi.nlm.nih.gov/nuccore/T76582.1', 'https://www.ncbi.nlm.nih.gov/nuccore/AAADR0018150.1', 'https://www.ncbi.nlm.nih.gov/nuccore/Z28054.1', 'https://www.ncbi.nlm.nih.gov/nuccore/BY951742.1', 'https://www.ncbi.nlm.nih.gov/nuccore/AAPY01442786.1']\n",
      "Concluido\n"
     ]
    }
   ],
   "source": [
    "#Extrair ids genebank:\n",
    "data_e_hora_atuais = datetime.now()\n",
    "\n",
    "query= input('escolha o que quer pesquisar: ')\n",
    "\n",
    "def url_get(i):\n",
    "    url_list= [ ]\n",
    "    url = \"https://www.ncbi.nlm.nih.gov/gene/?term={}\".format( query )\n",
    "    url_list.append(url)\n",
    "    return url_list\n",
    "url_get(1)\n",
    "\n",
    "content = []\n",
    "for url in url_get(1):\n",
    "    r = requests.get(url)\n",
    "    content.append(r.content)\n",
    "    \n",
    "for c in content:\n",
    "    soup = BeautifulSoup(c, 'html.parser')\n",
    "    a= soup.get_text()\n",
    "    \n",
    "existe = re.findall(r\"ID:\\s+\\d*(?=\\D)\", a, re.DOTALL)\n",
    "\n",
    "c= ', '.join(existe)\n",
    "h= c.replace('ID: ','')\n",
    "IDS= h.split(', ')\n",
    "\n",
    "n_gene= IDS[0:int(input('escolha o nº de genes que quer obter (máximo 20): '))]\n",
    "\n",
    "n_genes = []\n",
    "seen = set()\n",
    "for item in n_gene:\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        n_genes.append(item)\n",
    "        \n",
    "numero_genes= len(n_genes)\n",
    "\n",
    "#Extrair ids ncbi:\n",
    "Ids=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    Ids.append(info.id)\n",
    "\n",
    "#Extrair description NCBI:\n",
    "description=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    description.append(info.description)\n",
    "\n",
    "#organismos\n",
    "Organismos=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    Organismos.append(info.annotations['organism'])\n",
    "    \n",
    "#SEQ\n",
    "seqss=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    seqs= (f'{info.seq[0:10]}...{info.seq[-10:]}')\n",
    "    seqss.append(seqs)\n",
    "\n",
    "#percentagem de nucle:\n",
    "Adenina=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    c=info.seq\n",
    "    count= c.count('A')\n",
    "    perc= int(count/len(c)*100)\n",
    "    Adenina.append(perc)\n",
    "\n",
    "Citosina=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    c=info.seq\n",
    "    count= c.count('C')\n",
    "    perc= int(count/len(c)*100)\n",
    "    Citosina.append(perc)\n",
    "\n",
    "Guanina=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    c=info.seq\n",
    "    count= c.count('G')\n",
    "    perc= int(count/len(c)*100)\n",
    "    Guanina.append(perc)\n",
    "\n",
    "Timina=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    c=info.seq\n",
    "    count= c.count('T')\n",
    "    perc= int(count/len(c)*100)\n",
    "    Timina.append(perc)\n",
    "    \n",
    "#data\n",
    "dates=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    dates.append(info.annotations['date'])\n",
    "\n",
    "#len(SEQ)\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "tam=[]\n",
    "for info in records:\n",
    "    tam.append(len(info.seq))\n",
    "    \n",
    "# buscar info pubmed\n",
    "\n",
    "def url_get_id(i):\n",
    "    url_list= [ ]\n",
    "    for id in i:\n",
    "        url = \"https://www.ncbi.nlm.nih.gov/nuccore/{}\".format( id )\n",
    "        url_list.append(url)\n",
    "    return url_list\n",
    "link_genebank= url_get_id(Ids)\n",
    "print(link_genebank)\n",
    "\n",
    "content_id = []\n",
    "for url in url_get_id(Ids):\n",
    "    r_id = requests.get(url)\n",
    "    content_id.append(r_id.content)\n",
    "    \n",
    "from bs4 import BeautifulSoup\n",
    "listas=[]\n",
    "\n",
    "for c in content_id:\n",
    "    soup_id = BeautifulSoup(c, 'html.parser')\n",
    "\n",
    "    lines = soup_id.find_all('meta', {'name':\"ncbi_uidlist\"} )\n",
    "\n",
    "    id = \"\"\n",
    "    url = \"\"\n",
    "    for line in lines:\n",
    "        if 'content' in line.attrs:\n",
    "            id = line.attrs['content']\n",
    "    if id:\n",
    "        url = \"https://www.ncbi.nlm.nih.gov/sviewer/viewer.fcgi?id={}&db=nuccore&report=genbank&conwithfeat=on&hide-cdd=on&retmode=text&maxdownloadsize=5000000\".format(id)\n",
    "    r2 = requests.get(url)\n",
    "    r4= r2.content.decode('utf-8')\n",
    "    listas.append(r4)\n",
    "    \n",
    "cc= ', '.join(listas)\n",
    "er= cc.replace('//','')\n",
    "final= er.split(', ')\n",
    "\n",
    "#criar dicionário de ids ncbi e ids pubmed\n",
    "output_dict = {}\n",
    "for x in final:\n",
    "    version = re.search(r'VERSION\\s+(.*?)\\s', x)\n",
    "    pubmed = re.search(r'PUBMED\\s+(.*?)\\s', x)\n",
    "    if version:\n",
    "        versionf=version.group(1)\n",
    "        output_dict.setdefault(version.group(1), [])\n",
    "    if pubmed:\n",
    "        output_dict[versionf].append(pubmed.group(1))\n",
    "\n",
    "#Criar Listas só com ids ncbi e ids pubmed\n",
    "id_ncbii = []\n",
    "ID_PUB = []\n",
    "for key, vals in output_dict.items():\n",
    "    if vals:\n",
    "        for val in vals:\n",
    "            id_ncbii.append(key)\n",
    "            ID_PUB.append(val)\n",
    "    else:\n",
    "        id_ncbii.append(key)\n",
    "        ID_PUB.append(\"N/A\")\n",
    "\n",
    "new_list_ = []\n",
    "seen = set()\n",
    "for item in ID_PUB:\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        new_list_.append(item)\n",
    "\n",
    "print(\"Concluido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "949a591d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function url_get_id_p at 0x00000173E3F1BCA0>\n",
      "['CAA24252.1', 'CAA47407.1', 'CAA78750.1', 'CAA24617.1']\n",
      "{'Z17674.1': 'N/A_CDS', 'V00883.1': 'CAA24252.1', 'X67017.1': 'CAA47407.1', 'X61243.1': 'N/A_CDS', 'M90830.1': 'N/A_CDS', 'Z15032.1': 'CAA78750.1', 'V01310.1': 'CAA24617.1', 'M94340.1': 'N/A_CDS'}\n",
      "[['N/A_CDS', 'N/A', 'N/A'], [\"['CAA24252.1']\", ['[223 : 316]', '[440 : 662]', '[1479 : 1608]'], \"['MVHFTAEEKAAITSTWKLVDVEDAGAEALGRLLVVYPWTQRFFDSFGNLSSSSAIMGNPKVKAHGKKVLTAFGDAVKNVDDLKNTFAHLSELHCDRLHVDPENFKLLGNVLVIVLAKYFGKEFTPQVQSAWQKLVAGVATALAHKYH']\"], [\"['CAA47407.1']\", '[246 : 921]', \"['MMSSDQQGKCPVDEETKKLWLREHGNEAHPGATAPGNQLECSANPQDNDKTPEYHTTVDLSQSREVSTIPRTNSDRNWIYPSEKQFYEAMMKKNWDPNSDDMKVVVPLHNSINERVWNYIKSWEDKQGGEACGGIKLTNFKGDSKKLTPRAWFRSRILHLAKPFDRHDWQIDRCGKTVDYVIDFYSTDLNDANSQQQPLIYLDVRPKLNSFEGFRLRFWKSLGF']\"], ['N/A_CDS', 'N/A', 'N/A'], ['N/A_CDS', 'N/A', 'N/A'], [\"['CAA78750.1']\", '[<0 : >228]', \"['STSKSQILQYVHKITPRGVYTSGKGSSAVGLTAYITRDVDTKQLVLESGALVLSDGGVCCIDEFDKMSDSTRSVLH']\"], [\"['CAA24617.1']\", '[1331 : 3731]', \"['MVLPILPLIDDLASWNSKKEYVSLVGQVLLDGSSLSNEEILQFSKEEEVPLVRLSLPSGKFSDDEIIAFLNNGVSSLFIASQDAKTAEHLVEQLNVPKERVVVEENGVFSNQFMVKQKFSQDKIVSIKKLSKDMLTKEVLGEVRTDRPDGLYTTLVVDQYERCLGLVYSSKKSIAKAIDLGRGVYYSRSRNEIWIKGETSGNGQKLLQISTDCDSDALKFIVEQENVGFCHLETMSCFGEFKHGLVGLESLLKQRLQDAPEESYTRRLFNDSALLDAKIKEEAEELTEAKGKKELSWEAADLFYFALAKLVANDVSLKDVENNLNMKHLKVTRRKGDAKPKFVGQPKAEEEKLTGPIHLDVVKASDKVGVQKALSRPIQKTSEIMYLVNPIIENVRDKGNSVFLEYTEKFDGVKLSNPVLNAPFPEEYFEGLTEEMKEALNLSIENVRKFHAAQLPTETLEVETQPGVLCSRFPRPIEKVGLYIPGGTAILPSTALMLGVPAQVAQCKEIVFASPPRKSDGKVSPEVVYVAEKVGASKIVLAGGAQAVAAMAYGTETIPKVDKILGPGNQFVTAAKMYVQNDTQALCSIDMPAGPSEVLVIADEDADVDFVASDLLSQAEHGIDSQVILVGVNLSEKKIQEIQDAVHNQALQLPRVDIVRKCIAHSTIVLCDGYEEALEMSNQYAPEHLILQIANANDYVKLVDNAGSVFVGAYTPESCGDYSSGTNHTLPTYGYARQYSGANTATFQKFITAQNITPEGLENIGRAVMCVAKKEGLDGHRNAVKIRMSKLGLFPKDFQ']\"], ['N/A_CDS', 'N/A', 'N/A']]\n",
      "Concluido\n"
     ]
    }
   ],
   "source": [
    "#Extrair informação de artigos\n",
    "\n",
    "titles=[]\n",
    "authors=[]\n",
    "source=[]\n",
    "affiliation=[]\n",
    "database = 'PubMed'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= new_list_\n",
    "counter = 0\n",
    "for i in idlist:\n",
    "    if i!= \"N/A\":\n",
    "        handle = Entrez.efetch(db=database, id=i, rettype=\"medline\", retmode=\"text\") \n",
    "        records = Medline.parse(handle)\n",
    "        for info in records:\n",
    "            titles.append(info.get(\"TI\", [\"N/A\"]))\n",
    "            authors_string = info.get(\"AU\", [\"N/A\"])\n",
    "            if len(authors_string) > 5:\n",
    "                authors_h = authors_string[0:5]\n",
    "                authors.append(authors_h)\n",
    "            else:\n",
    "                authors.append(authors_string) \n",
    "            source.append(info.get(\"SO\", [\"N/A\"]))\n",
    "            affiliation_string= info.get(\"AD\", [\"N/A\"])\n",
    "            if len(affiliation_string) > 5:\n",
    "                affiliation_h = affiliation_string[0:5]\n",
    "                affiliation.append(affiliation_h)\n",
    "            else:\n",
    "                affiliation.append(affiliation_string)\n",
    "            counter += 1\n",
    "    else:\n",
    "        titles.append([\"N/A\"])\n",
    "        authors.append([\"N/A\"])\n",
    "        source.append([\"N/A\"])\n",
    "        affiliation.append([\"N/A\"])\n",
    "        counter += 1\n",
    "        \n",
    "#agrupar titles\n",
    "titles = [ [title] for title in titles]\n",
    "\n",
    "# agrupar dois\n",
    "doi_list = []\n",
    "for x in source:\n",
    "    match = re.search(\"doi: (.*)\", str(x))\n",
    "    if match:\n",
    "        doi_list.append(match.group(1))\n",
    "    else:\n",
    "        doi_list.append(\"N/A\")\n",
    "        \n",
    "#agrupar authors\n",
    "id_authors_dict = {i: authors[counter] if i != \"N/A\" else [\"N/A\"] for counter, i in enumerate(idlist)}        \n",
    "        \n",
    "pubmed_list = []\n",
    "authors_list = []\n",
    "for key, vals in id_authors_dict.items():\n",
    "    if vals:\n",
    "        for val in vals:\n",
    "            pubmed_list.append(key)\n",
    "            authors_list.append(val)\n",
    "\n",
    "new_list_authors= []\n",
    "seen = set()\n",
    "for item in authors_list:\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        new_list_authors.append(item)\n",
    "\n",
    "#agrupar affi\n",
    "single_affiliation_list = []\n",
    "for i in affiliation:\n",
    "    single_affiliation_list.extend(i)\n",
    "    \n",
    "\n",
    "id_affiliation_dict = {i: [single_affiliation_list[counter]] if i != \"N/A\" else [\"N/A\"] for counter, i in enumerate(idlist)}\n",
    "\n",
    "pubmed_affi_list = []\n",
    "affi_list = []\n",
    "for key, vals in id_affiliation_dict.items():\n",
    "    if vals:\n",
    "        for val in vals:\n",
    "            pubmed_affi_list.append(key)\n",
    "            affi_list.append(val)\n",
    "    else:\n",
    "        pubmed_affi_list.append(key)\n",
    "        affi_list.append([\"N/A\"])\n",
    "\n",
    "new_list_affi= []\n",
    "seen = set()\n",
    "for item in single_affiliation_list :\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        new_list_affi.append(item)\n",
    "\n",
    "#FINAL (usado em baixo) - NECESSÁRIO\n",
    "def url_get_id_p(string):\n",
    "#     print(string)\n",
    "    url_list_p=[ ]\n",
    "    url_id_p= \"https://www.uniprot.org/uniprotkb/{}/entry\".format(str(string))\n",
    "    url_list_p.append(url_id_p)\n",
    "    return ''.join(url_list_p)\n",
    "print(url_get_id_p)\n",
    "\n",
    "#FINAL para protein_id - PROT_ID (NECESSÁRIO)\n",
    "list_pro=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    for i in info.features:\n",
    "        if i.type == \"CDS\":\n",
    "            pro= str(i.qualifiers[\"protein_id\"])\n",
    "            list_pro.append(pro)\n",
    "div= ', '.join(list_pro)\n",
    "h= div.replace(\"['\",'')\n",
    "hh= h.replace(\"']\",'')\n",
    "ID_PROT= hh.split(', ')\n",
    "print (ID_PROT) # is used below in Uniprot\n",
    "\n",
    "def count_(genes):\n",
    "    return len(genes)\n",
    "count_(Ids)\n",
    "count_(ID_PROT)\n",
    "\n",
    "#FINAL result_dic = {Ids, ID_PROT} - NECESSÁRIO\n",
    "result_dict = {}\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist=Ids\n",
    "# idlist= Ids.remove('U49845')\n",
    "for ids in idlist:\n",
    "    list_pro=[]\n",
    "    handle = Entrez.efetch(db=database, id=ids, rettype=\"gb\") \n",
    "    records = list(SeqIO.parse(handle,\"gb\"))\n",
    "    handle.close()\n",
    "    for info in records:\n",
    "        list_pro.append(info.id)\n",
    "        for i in info.features:\n",
    "            if i.type == \"CDS\":\n",
    "                pro= str(i.qualifiers[\"protein_id\"])\n",
    "                list_pro.append(pro)\n",
    "        if len(list_pro)==1: #if no protein_id was found\n",
    "            result_dict[info.id] = \"N/A_CDS\"\n",
    "        else:\n",
    "            list_pro = [x.replace(\"['\",'').replace(\"']\",'') for x in list_pro]\n",
    "            result_dict[info.id] = ', '.join(list_pro[1:])\n",
    "print(result_dict)\n",
    "#key: id_genebank; values: id_Uniprot\n",
    "\n",
    "#FINAL para location, product e translation  - get_CDS_info(result_dict) = [id_protein, location,translation] - NECESSÁRIO\n",
    "\n",
    "def get_CDS_info(result_dict):\n",
    "    database = 'nucleotide'\n",
    "    email= 'rodrigoce9@gmail.com'\n",
    "    Entrez.email = email\n",
    "    cds_location_list = []\n",
    "    several_location = []\n",
    "    record_types={}\n",
    "    for i, value in result_dict.items():\n",
    "        cds_location =[]\n",
    "        if value == 'N/A_CDS':\n",
    "            cds_location.append(value)\n",
    "            cds_location.append('N/A')            \n",
    "            cds_location.append('N/A')                     \n",
    "            cds_location_list.append(cds_location)\n",
    "\n",
    "        else:\n",
    "            handle = Entrez.efetch(db=database, id=i, rettype=\"gb\") \n",
    "            records = list(SeqIO.parse(handle,\"gb\"))\n",
    "            handle.close()\n",
    "            for info in records:\n",
    "                for i in info.features:\n",
    "                    product, translation = '', ''\n",
    "                    if i.type == \"CDS\":\n",
    "                        i_d = str(i.qualifiers[\"protein_id\"])\n",
    "                        translation =  str(i.qualifiers[\"translation\"])\n",
    "                        cds_location.append(i_d)\n",
    "                        if isinstance(i.location, CompoundLocation):\n",
    "                            for sub_location in i.location.parts:\n",
    "                                several_location.append(\"[{} : {}]\".format(sub_location.start, sub_location.end))\n",
    "                            cds_location.append(several_location)\n",
    "                            cds_location.append(translation)\n",
    "                        else:\n",
    "                            cds_location.append(\"[{} : {}]\".format(i.location.start, i.location.end))\n",
    "                            cds_location.append(translation)\n",
    "                        cds_location_list.append(cds_location)      \n",
    "                \n",
    "            handle.close()\n",
    "    return cds_location_list\n",
    "print(get_CDS_info(result_dict))\n",
    "\n",
    "#FINAL - NECESSÁRIO\n",
    "WEBSITE_API = \"https://rest.uniprot.org\"\n",
    "fields = [\"accession\",\"organism_name\",\"protein_name\",\"cc_subcellular_location\",\"cc_function\", \"sequence\"]\n",
    "def get_url(url, **kwargs):\n",
    "    response = requests.get(url, **kwargs);\n",
    "    if not response.ok:\n",
    "        print(response.text)\n",
    "        response.raise_for_status()\n",
    "        sys.exit()\n",
    "    return response\n",
    "\n",
    "def get_field_for_id(ID_PROT, field):\n",
    "    response = get_url(\"{}/uniprotkb/search?query={}&fields={}&size=1&format=tsv\".format(WEBSITE_API,ID_PROT,field))\n",
    "    return str(response.content)\n",
    "#############################BUG AQUI#########################################\n",
    "def get_list_uniprot(ID_PROT, result_dict):\n",
    "    results = {}\n",
    "    result = {}\n",
    "    for first_key, first_value in result_dict.items(): \n",
    "        result = {}\n",
    "        for field in fields:\n",
    "            if first_value != 'N/A_CDS':\n",
    "                result[field] = get_field_for_id(first_value, field)\n",
    "            else:\n",
    "                result[field] = 'N/A_Uniprot'\n",
    "            results[first_key] = result   \n",
    "#############################BUG AQUI#########################################    \n",
    "    uniprot_final_list=[]\n",
    "    for key, value in results.items():\n",
    "        uniprot_list=[]\n",
    "        for x in value.values():\n",
    "#             print(key)\n",
    "            entry = re.search(r'b\\'Entry\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL)\n",
    "            function = re.match( r'b\\'Function \\[CC\\]\\\\n.{9} (.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "            location_exist = re.search( r'b\\'Subcellular location \\[CC\\]\\\\nSUBCELLULAR LOCATION: (.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "            location_notexist = re.search( r'b\\'Subcellular location \\[CC\\]\\\\n\\\\n\\'', x, re.DOTALL )   \n",
    "            sequence = re.search(r'b\\'Sequence\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL)\n",
    "            n_a = re.search(r'(N/A_Uniprot)', x, re.DOTALL)\n",
    "            if entry:\n",
    "                ent=entry.group(1)\n",
    "                uniprot_list.append(entry.group(1))            \n",
    "            if function:\n",
    "                uniprot_list.append(function.group(1))\n",
    "#                 print(function.group(0))\n",
    "#             if not function:\n",
    "#                 print('na')\n",
    "            if location_exist:\n",
    "                uniprot_list.append(location_exist.group(1))\n",
    "            if location_notexist:\n",
    "                uniprot_list.append(\"N/A\")\n",
    "            if sequence:\n",
    "                uniprot_list.append(sequence.group(1))\n",
    "                uniprot_list.append(len(sequence.group(1)))\n",
    "                uniprot_list.append(url_get_id_p(ent))\n",
    "            if n_a:\n",
    "                uniprot_list.append(n_a.group(1))\n",
    "        uniprot_final_list.append(uniprot_list)\n",
    "#     if len(uniprot_final_list)    \n",
    "    return uniprot_final_list\n",
    "get_Uniprot=get_list_uniprot(ID_PROT,result_dict) #list of lists (ID_Uniprot, Function, Subcelular location, Protein seq, length_aa)\n",
    "\n",
    "WEBSITE_API = \"https://rest.uniprot.org\"\n",
    "fields = [\"accession\",\"organism_name\",\"protein_name\",\"cc_subcellular_location\",\"cc_function\", \"sequence\"]\n",
    "def get_url(url, **kwargs):\n",
    "    response = requests.get(url, **kwargs);\n",
    "    if not response.ok:\n",
    "        print(response.text)\n",
    "        response.raise_for_status()\n",
    "        sys.exit()\n",
    "    return response\n",
    "\n",
    "def get_field_for_id(ID_PROT, field):\n",
    "    response = get_url(\"{}/uniprotkb/search?query={}&fields={}&size=1&format=tsv\".format(WEBSITE_API,ID_PROT,field))\n",
    "    return str(response.content)\n",
    "\n",
    "def dict_to_list(d, delimiter=','):\n",
    "    new_list = []\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, str):\n",
    "            values = v.split(delimiter)\n",
    "            for val in values:\n",
    "                new_list.append([k, val.strip()])\n",
    "        else:\n",
    "            new_list.append([k, v])\n",
    "    return new_list\n",
    "dict_to_list(result_dict)\n",
    "\n",
    "def get_list_uniprot(ID_PROT, result_dict):\n",
    "    results = {}\n",
    "    result = {}\n",
    "    \n",
    "    easy=dict_to_list(result_dict)\n",
    "    \n",
    "    for first_index, first_value in easy:         \n",
    "        result = {}\n",
    "        for field in fields:\n",
    "            if first_value != 'N/A_CDS':\n",
    "                result[field] = get_field_for_id(first_value, field)\n",
    "            else:\n",
    "                result[field] = 'N/A_Uniprot'\n",
    "            results[first_index] = result   \n",
    "    \n",
    "    uniprot_final_list=[]\n",
    "    for key, value in results.items():\n",
    "        uniprot_list=[]\n",
    "        for x in value.values():\n",
    "#             print(key)\n",
    "            entry = re.search(r'b\\'Entry\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL)\n",
    "            function = re.match( r'b\\'Function \\[CC\\]\\\\n.{9} (.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "            location_exist = re.search( r'b\\'Subcellular location \\[CC\\]\\\\nSUBCELLULAR LOCATION: (.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "            location_notexist = re.search( r'b\\'Subcellular location \\[CC\\]\\\\n\\\\n\\'', x, re.DOTALL )   \n",
    "            sequence = re.search(r'b\\'Sequence\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL)\n",
    "            n_a = re.search(r'(N/A_Uniprot)', x, re.DOTALL)\n",
    "            if entry:\n",
    "                ent=entry.group(1)\n",
    "                uniprot_list.append(entry.group(1))            \n",
    "            if function:\n",
    "                uniprot_list.append(function.group(1))\n",
    "#                 print(function.group(0))\n",
    "#             if not function:\n",
    "#                 print('na')\n",
    "            if location_exist:\n",
    "                uniprot_list.append(location_exist.group(1))\n",
    "            if location_notexist:\n",
    "                uniprot_list.append(\"N/A\")\n",
    "            if sequence:\n",
    "                uniprot_list.append(sequence.group(1))\n",
    "                uniprot_list.append(len(sequence.group(1)))\n",
    "                uniprot_list.append(url_get_id_p(ent))\n",
    "            if n_a:\n",
    "                uniprot_list.append(n_a.group(1))\n",
    "        uniprot_final_list.append(uniprot_list)\n",
    "#     if len(uniprot_final_list)    \n",
    "    return uniprot_final_list\n",
    "get_Uniprot=get_list_uniprot(ID_PROT,result_dict)\n",
    "\n",
    "def dict_to_list(d, delimiter=','):\n",
    "    new_list = []\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, str):\n",
    "            values = v.split(delimiter)\n",
    "            for val in values:\n",
    "                new_list.append([k, val.strip()])\n",
    "        else:\n",
    "            new_list.append([k, v])\n",
    "    return new_list\n",
    "easy=dict_to_list(result_dict)\n",
    "\n",
    "#final, mas não correr (código necessário para o caso se querermos links não diretos para uniprot )\n",
    "#def url_get_id_p(dic):\n",
    "    #url_list_p = []\n",
    "    #for key, value in dic.items():\n",
    "        #if value != 'N/A_CDS':\n",
    "            #value_list = value.split(',')\n",
    "            #for val in value_list:\n",
    "                #val = val.strip()\n",
    "                #url_id_p = \"https://www.uniprot.org/uniprotkb?query={}\".format(val)\n",
    "                #url_list_p.append(url_id_p)\n",
    "    #return url_list_p\n",
    "#url_ids_protein=url_get_id_p(result_dict)\n",
    "#print(url_ids_protein) # but we don't need to save this links\n",
    "\n",
    "#FINAL [idgenebank, protein_id, id do uniprot]  -  NECESSÁRIO\n",
    "def join_ids_CDS(dic, uniprotID):\n",
    "    join_list_all = []\n",
    "    for key, value in dic.items():\n",
    "        join_list = []\n",
    "        join_list.append(key)\n",
    "        join_list.append(value)\n",
    "        join_list_all.append(join_list) \n",
    "    for index, values in enumerate(uniprotID):\n",
    "        join_list_all[index].append(uniprotID[index][0])\n",
    "    return join_list_all\n",
    "join_ids=join_ids_CDS(result_dict,get_list_uniprot(ID_PROT, result_dict))\n",
    "\n",
    "#final [idgenebank, protein_id, id_uniprot,location, product, translation] (NÃO SEI SE ESTÁ A FUNCAR DIREITO - assumir que não)\n",
    "def join_lists(list1, list2):\n",
    "    final_result =[]\n",
    "    \n",
    "    for item, value in enumerate(list1):\n",
    "        result = []\n",
    "        string_item = str(list2[item][0])\n",
    "        string_item = string_item.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\")\n",
    "        if list1[item][1] == string_item:\n",
    "            result.append(list1[item] + list2[item][1:])\n",
    "        else:\n",
    "            result.append(item1[item])\n",
    "        final_result.append(result)\n",
    "    return final_result\n",
    "join_CDS=join_lists(join_ids, get_CDS_info(result_dict))\n",
    "\n",
    "print(\"Concluido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "40bbca2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concluido\n"
     ]
    }
   ],
   "source": [
    "#Povoação \"History\"\n",
    "\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "    sql= \"INSERT INTO History (search, Genes_number_input, Day, Genes_number_NCBI, Protein_number  )   VALUES (%s, %s, %s, %s, %s)\"\n",
    "    val=(query, numero_genes, data_e_hora_atuais, count_(Ids), count_(ID_PROT) )\n",
    "    Cursor.execute(sql,val)\n",
    "    \n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()\n",
    "    \n",
    "search_id =[]\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "    sql= \"Select ID_search FROM History\"\n",
    "    Cursor.execute(sql)\n",
    "    for row in Cursor:\n",
    "        search_id.append(str(row)) \n",
    "        \n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()\n",
    "    \n",
    "div= ', '.join(search_id)\n",
    "h= div.replace(\"(\",'')\n",
    "hh= h.replace(\",)\",'')\n",
    "SEARCH_ID= hh.split(', ')\n",
    "Hist= SEARCH_ID[-1]\n",
    "\n",
    "#Povoação \"Gene\"-\n",
    "\n",
    "des = (description)\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "    for index, value in enumerate(Ids):\n",
    "        #print(value)\n",
    "        #print(des[index])\n",
    "        sql= \"INSERT INTO Gene (ID_genebank, Description, Organism, sequence, Date_publish, length, Adenina, Citosina, Guanina, Timina, Link, ID_search) VALUES ( %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "        val=(value, des[index], Organismos[index], seqss[index], dates[index], tam[index], Adenina[index], Citosina[index], Guanina[index], Timina[index], link_genebank[index], Hist)\n",
    "#         print(type(des[index]))\n",
    "        Cursor.execute(sql,val)\n",
    "#         for values in des:\n",
    "#             Cursor.execute(f\"INSERT INTO Gene ( Description)  VALUES ('{values}')\")\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()\n",
    "    \n",
    "#Povoar \"PubMed\"\n",
    "\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "    for index, value in enumerate(new_list_):\n",
    "        #print(value)\n",
    "        #print(des[index])\n",
    "        sql= \"INSERT INTO PubMed (ID_PumMed, title, Doi_number) VALUES (%s, %s, %s)\"\n",
    "        val=(str(new_list_[index]), str(titles[index]), str(doi_list[index]) )\n",
    "#         print(type(des[index]))\n",
    "        Cursor.execute(sql,val)\n",
    "#         for values in des:\n",
    "#             Cursor.execute(f\"INSERT INTO Gene ( Description)  VALUES ('{values}')\")\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()\n",
    "    \n",
    "#retirar os valores AI de pubmed\n",
    "ID_AI=[]\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "    sql= \"Select ID_AI_PubMed FROM PubMed\"\n",
    "    Cursor.execute(sql)\n",
    "    for row in Cursor:\n",
    "        #print(row)\n",
    "        ID_AI.append(str(row))       \n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()\n",
    "    \n",
    "   \n",
    "div_= ', '.join(ID_AI)\n",
    "h_= div_.replace(\"(\",'')\n",
    "hh_= h_.replace(\",)\",'')\n",
    "SEARCH_ID_= hh_.split(', ')\n",
    "#print(SEARCH_ID_)\n",
    "\n",
    "#Povação \"Gene-Pubmed\"\n",
    "number_map = {}\n",
    "next_number = int(SEARCH_ID_[0])\n",
    "relation = []\n",
    "for number in ID_PUB:\n",
    "    if number not in number_map:\n",
    "        number_map[number] = next_number\n",
    "        next_number += 1\n",
    "    relation.append(number_map[number])\n",
    "    \n",
    "\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "    for index, value in enumerate(id_ncbii):\n",
    "        \n",
    "        sql= \"INSERT INTO gene_PubMed (ID_genebank, ID_AI_PubMed) VALUES (%s, %s)\"\n",
    "        val=(id_ncbii[index], relation[index])\n",
    "    \n",
    "        Cursor.execute(sql,val)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()\n",
    "    \n",
    "#Povação \"authors\"\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "    for index, value in enumerate(new_list_authors):\n",
    "        \n",
    "        sql= \"INSERT INTO Authors (Name) VALUES (%s)\"\n",
    "        val=(new_list_authors[index],)\n",
    "    \n",
    "        Cursor.execute(sql,val)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()\n",
    "\n",
    "#retirar os valores AI de authors\n",
    "ID_AI_Authors=[]\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "    sql= \"Select ID_Authors FROM Authors\"\n",
    "    Cursor.execute(sql)\n",
    "    for row in Cursor:\n",
    "        #print(row)\n",
    "        ID_AI_Authors.append(str(row))       \n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()\n",
    "    \n",
    "div_Authors= ', '.join(ID_AI_Authors)\n",
    "h_Authors= div_Authors.replace(\"(\",'')\n",
    "hh_Authors= h_Authors.replace(\",)\",'')\n",
    "SEARCH_ID_Authors= hh_Authors.split(', ')\n",
    "#print(SEARCH_ID_Authors)\n",
    "\n",
    "#Povação \"Pubmed-Authors\"\n",
    "number_map_ = {}\n",
    "next_number = int(SEARCH_ID_Authors[0])\n",
    "output_authors = []\n",
    "for number in authors_list:\n",
    "    if number not in number_map_:\n",
    "        number_map_[number] = next_number\n",
    "        next_number += 1\n",
    "    output_authors.append(number_map_[number])\n",
    "\n",
    "number_map_pub = {}\n",
    "next_number = int(SEARCH_ID_[0])\n",
    "output_pub = []\n",
    "for number in pubmed_list:\n",
    "    if number not in number_map_pub:\n",
    "        number_map_pub[number] = next_number\n",
    "        next_number += 1\n",
    "    output_pub.append(number_map_pub[number])\n",
    "\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "    for index, value in enumerate(output_pub):\n",
    "        \n",
    "        sql= \"INSERT INTO PubMed_Authors (ID_AI_PubMed, ID_Authors) VALUES (%s, %s)\"\n",
    "        val=(str(output_pub[index]),str(output_authors[index]))\n",
    "    \n",
    "        Cursor.execute(sql,val)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()\n",
    "    \n",
    "#Povação \"affi\"\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "    for index, value in enumerate(new_list_affi):\n",
    "        \n",
    "        sql= \"INSERT INTO Affiliation (Info) VALUES (%s)\"\n",
    "        val=(new_list_affi[index],)\n",
    "    \n",
    "        Cursor.execute(sql,val)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()\n",
    "\n",
    "    \n",
    "#retirar os valores AI de affi\n",
    "ID_AI_Affiliation=[]\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "    sql= \"Select ID_Affiliation FROM Affiliation\"\n",
    "    Cursor.execute(sql)\n",
    "    for row in Cursor:\n",
    "        #print(row)\n",
    "        ID_AI_Affiliation.append(str(row))       \n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()\n",
    "    \n",
    "div_Affiliation= ', '.join(ID_AI_Affiliation)\n",
    "h_Affiliation= div_Affiliation.replace(\"(\",'')\n",
    "hh_Affiliation= h_Affiliation.replace(\",)\",'')\n",
    "SEARCH_ID_Affiliation= hh_Affiliation.split(', ')\n",
    "#print(SEARCH_ID_Affiliation)\n",
    "\n",
    "#Povação \"Pubmed-Affiliation\"\n",
    "number_map_affi_pub = {}\n",
    "next_number = int(SEARCH_ID_[0])\n",
    "output_pub_affi = []\n",
    "for number in pubmed_affi_list:\n",
    "    if number not in number_map_affi_pub:\n",
    "        number_map_affi_pub[number] = next_number\n",
    "        next_number += 1\n",
    "    output_pub_affi.append(number_map_affi_pub[number])\n",
    "    \n",
    "number_map_affi = {}\n",
    "next_number = int(SEARCH_ID_Affiliation[0])\n",
    "output_affi = []\n",
    "for number in affi_list:\n",
    "    if number not in number_map_affi:\n",
    "        number_map_affi[number] = next_number\n",
    "        next_number += 1\n",
    "    output_affi.append(number_map_affi[number])\n",
    "\n",
    "\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "    for index, value in enumerate(output_pub_affi):\n",
    "        \n",
    "        sql= \"INSERT INTO PubMed_Affiliation (ID_AI_PubMed, ID_Affiliation) VALUES (%s, %s)\"\n",
    "        val=(str(output_pub_affi[index]),str(output_affi[index]))\n",
    "    \n",
    "        Cursor.execute(sql,val)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()\n",
    "\n",
    "print(\"Concluido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e0e00f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro na escrita na base de dados: 1062 (23000): Duplicate entry 'N/A_Uniprot' for key 'PRIMARY'\n",
      "Erro na escrita na base de dados: 1062 (23000): Duplicate entry 'N/A_CDS' for key 'PRIMARY'\n"
     ]
    }
   ],
   "source": [
    "#Povoação \"Uniprot\" \n",
    "# print(get_Uniprot) #(ID_Uniprot, Subcelular location, Function, Protein seq, length_aa)\n",
    "\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "#     sql = \"ALTER TABLE Uniprot AUTO_INCREMENT = 0\"\n",
    "#     Cursor.execute(sql)\n",
    "    for index in get_Uniprot:\n",
    "        #print(value)\n",
    "        sql= \"INSERT INTO Uniprot (ID_Uniprot, Subcelular_Location, Function, Protein_sequence, length_aa, Link_Uniprot) VALUES (%s, %s, %s, %s, %s, %s)\"\n",
    "        val=(str(index[0]), str(index[1]), str(index[2]), str(index[3]), str(index[4]), str(index[5]))\n",
    "        Cursor.execute(sql,val)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()\n",
    "    \n",
    "#Povoação \"CDS\"\n",
    "\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "    for index in join_CDS:\n",
    "        for item in index:\n",
    "            sql= \"INSERT INTO CDS (ID_CDS, Translation, Location, ID_genebank, ID_Uniprot) VALUES (%s, %s, %s, %s, %s)\"\n",
    "            val=(item[1],item[4],item[3],item[0],item[2])\n",
    "            Cursor.execute(sql,val)\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d328f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTES IMPORTANTES PARA DUPLICADOS\n",
    "AA=[[\"BA\",\"NA\",\"NA\",\"NA\",\"NA\",\"NA\"],[\"N/A\",\"N/A\",\"N/A\",\"N/A\",\"N/A\",\"N/A\"]]\n",
    "a=[\"N/A\"]\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "    sec = 'INSERT INTO Uniprot (ID_Uniprot) VALUES (%s)'\n",
    "    Cursor.execute(sec, a)\n",
    "    for i, a in enumerate(AA):\n",
    "        if AA[i][0] == 'N/A':\n",
    "            continue\n",
    "        else:\n",
    "            sql= 'INSERT INTO Uniprot (ID_Uniprot, Subcelular_Location, function, Protein_sequence, length_aa, Link_Uniprot) VALUES (%s, %s, %s, %s, %s, %s)'\n",
    "            val=(AA[i][0],AA[i][1],AA[i][2],AA[i][3],AA[i][4],AA[i][5])\n",
    "            Cursor.execute(sql,val)\n",
    "\n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "96c4b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Limpar todos os dados exceto o historico \n",
    "\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "        \n",
    "        a= \"delete from PubMed_Affiliation\"\n",
    "        Z= \"delete from PubMed_Authors\"\n",
    "        b= \"delete from Affiliation\"\n",
    "        c= \"delete from Authors\"\n",
    "        d= \"delete from gene_PubMed\"\n",
    "        e= \"delete from PubMed\"\n",
    "        f= \"delete from CDS\"\n",
    "        g= \"delete from Uniprot\"\n",
    "        h= \"delete from Gene\"    \n",
    "        \n",
    "        Cursor.execute(a)\n",
    "        Cursor.execute(Z)\n",
    "        Cursor.execute(b)\n",
    "        Cursor.execute(c)\n",
    "        Cursor.execute(d)\n",
    "        Cursor.execute(e)\n",
    "        Cursor.execute(f)\n",
    "        Cursor.execute(g)\n",
    "        Cursor.execute(h)\n",
    "        \n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "05afcd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete de tudo \n",
    "\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "DataBase.autocommit = True # allows the change be done\n",
    "\n",
    "Cursor = DataBase.cursor()\n",
    "try:\n",
    "        \n",
    "        a= \"delete from PubMed_Affiliation\"\n",
    "        Z= \"delete from PubMed_Authors\"\n",
    "        b= \"delete from Affiliation\"\n",
    "        c= \"delete from Authors\"\n",
    "        d= \"delete from gene_PubMed\"\n",
    "        e= \"delete from PubMed\"\n",
    "        f= \"delete from CDS\"\n",
    "        g= \"delete from Uniprot\"\n",
    "        h= \"delete from Gene\"\n",
    "        i= \"delete from History\"     \n",
    "        \n",
    "        Cursor.execute(a)\n",
    "        Cursor.execute(Z)\n",
    "        Cursor.execute(b)\n",
    "        Cursor.execute(c)\n",
    "        Cursor.execute(d)\n",
    "        Cursor.execute(e)\n",
    "        Cursor.execute(f)\n",
    "        Cursor.execute(g)\n",
    "        Cursor.execute(h)\n",
    "        Cursor.execute(i)\n",
    "        \n",
    "except mysql.connector.Error as e:\n",
    "    print(\"Erro na escrita na base de dados: {}\".format(e) )    \n",
    "finally:\n",
    "    DataBase.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2b526726",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID_search Search  Genes_number_input                 Day  \\\n",
      "0         11  virus                   8 2023-01-18 17:26:21   \n",
      "\n",
      "   Genes_number_NCBI  Protein_number  \n",
      "0                  4               3  \n",
      "\n",
      "\n",
      "\n",
      "  ID_genebank                                        Description  \\\n",
      "0    V01302.1  Yeast gene encoding glyceraldehyde-3-phosphate...   \n",
      "1    V01321.1                Yeast gene encoding pyruvate kinase   \n",
      "2    X67705.1    S.cerevisiae SWP1 gene for suppressor of wbp1-2   \n",
      "3    Z20017.1  HSAAABFUO B, Human Liver tissue Homo sapiens c...   \n",
      "\n",
      "                   Organism date_publish                 sequence  length  \\\n",
      "0  Saccharomyces cerevisiae  18-APR-2005  AGCCACCATC...AAGATTAGCA    1415   \n",
      "1  Saccharomyces cerevisiae  12-SEP-1993  GATCCAAATG...AAAAATGACG    2885   \n",
      "2  Saccharomyces cerevisiae  14-JAN-1993  CTGCAGCAAC...ACTGGGATCC    1739   \n",
      "3              Homo sapiens  07-FEB-1995  TTCCTTTAAA...CTTGTAAACC     223   \n",
      "\n",
      "   Adenina  Citosina  Timina  Guanina  \\\n",
      "0       28        21      28       21   \n",
      "1       29        21      30       19   \n",
      "2       30        22      29       17   \n",
      "3       30        19      30       20   \n",
      "\n",
      "                                            Link  ID_search  \n",
      "0  https://www.ncbi.nlm.nih.gov/nuccore/V01302.1         11  \n",
      "1  https://www.ncbi.nlm.nih.gov/nuccore/V01321.1         11  \n",
      "2  https://www.ncbi.nlm.nih.gov/nuccore/X67705.1         11  \n",
      "3  https://www.ncbi.nlm.nih.gov/nuccore/Z20017.1         11  \n",
      "\n",
      "\n",
      "\n",
      "  ID_genebank  ID_AI_PubMed\n",
      "0    V01302.1            85\n",
      "1    V01321.1            88\n",
      "2    X67705.1            86\n",
      "3    Z20017.1            87\n",
      "\n",
      "\n",
      "   ID_AI_PubMed                                              Title ID_PumMed  \\\n",
      "0            85  [\"Homologous nucleotide sequences at the 5' te...   6833300   \n",
      "1            86  ['Yeast Wbp1p and Swp1p form a protein complex...   8428586   \n",
      "2            87                                          [['N/A']]       N/A   \n",
      "3            88  ['The isolation, characterization, and sequenc...   6185493   \n",
      "\n",
      "                            Doi_number  \n",
      "0                                  N/A  \n",
      "1  10.1002/j.1460-2075.1993.tb05654.x.  \n",
      "2                                  N/A  \n",
      "3                                  N/A  \n",
      "\n",
      "\n",
      "\n",
      "    ID_AI_PubMed  ID_Authors\n",
      "0             85         262\n",
      "1             85         263\n",
      "2             85         264\n",
      "3             85         265\n",
      "4             86         266\n",
      "5             86         267\n",
      "6             86         268\n",
      "7             86         269\n",
      "8             87         270\n",
      "9             88         271\n",
      "10            88         272\n",
      "11            88         273\n",
      "\n",
      "\n",
      "\n",
      "    ID_Authors            Name\n",
      "0          262      Holland JP\n",
      "1          263     Labieniec L\n",
      "2          264       Swimmer C\n",
      "3          265      Holland MJ\n",
      "4          266     te Heesen S\n",
      "5          267        Knauer R\n",
      "6          268         Lehle L\n",
      "7          269          Aebi M\n",
      "8          270             N/A\n",
      "9          271        Burke RL\n",
      "10         272  Tekamp-Olson P\n",
      "11         273      Najarian R\n",
      "\n",
      "\n",
      "\n",
      "   ID_AI_PubMed                                              Title ID_PumMed  \\\n",
      "0            85  [\"Homologous nucleotide sequences at the 5' te...   6833300   \n",
      "1            86  ['Yeast Wbp1p and Swp1p form a protein complex...   8428586   \n",
      "2            87                                          [['N/A']]       N/A   \n",
      "3            88  ['The isolation, characterization, and sequenc...   6185493   \n",
      "\n",
      "                            Doi_number  \n",
      "0                                  N/A  \n",
      "1  10.1002/j.1460-2075.1993.tb05654.x.  \n",
      "2                                  N/A  \n",
      "3                                  N/A  \n",
      "\n",
      "\n",
      "\n",
      "   ID_AI_PubMed  ID_affiliation\n",
      "0            85              65\n",
      "1            87              65\n",
      "2            88              65\n",
      "3            86              66\n",
      "\n",
      "\n",
      "\n",
      "   ID_Affiliation                                               Info\n",
      "0              65                                                N/A\n",
      "1              66  Institut fur Molekularbiologie I, Universitat ...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n",
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "DataBase = SQLC.connect(\n",
    "    host =\"geo.di.uminho.pt\",\n",
    "    user =\"bioinformatica\",\n",
    "    password =\"20221207\",\n",
    "    database =\"AP_db_KRG\"\n",
    ")\n",
    "\n",
    "tabela1 = pd.read_sql(\"Select * FROM History\", DataBase)\n",
    "print(tabela1)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "tabela2 = pd.read_sql(\"Select * FROM Gene\", DataBase)\n",
    "print(tabela2)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "tabela3 = pd.read_sql(\"Select * FROM gene_PubMed\", DataBase)\n",
    "print(tabela3)\n",
    "print()\n",
    "print()\n",
    "tabela4 = pd.read_sql(\"Select * FROM PubMed\", DataBase)\n",
    "print(tabela4)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "tabela5 = pd.read_sql(\"Select * FROM PubMed_Authors\", DataBase)\n",
    "print(tabela5)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "tabela6 = pd.read_sql(\"Select * FROM Authors\", DataBase)\n",
    "print(tabela6)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "tabela7 = pd.read_sql(\"Select * FROM PubMed\", DataBase)\n",
    "print(tabela7)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "tabela8 = pd.read_sql(\"Select * FROM PubMed_Affiliation\", DataBase)\n",
    "print(tabela8)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "tabela9 = pd.read_sql(\"Select * FROM Affiliation\", DataBase)\n",
    "print(tabela9)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "#tabela10 = pd.read_sql(\"Select * FROM CDS\", DataBase)\n",
    "#print(tabela10)\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "#tabela11 = pd.read_sql(\"Select * FROM Uniprot\", DataBase)\n",
    "#print(tabela11)\n",
    "DataBase.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693f3390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
