{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Blast import NCBIXML \n",
    "from Bio.Blast import NCBIWWW\n",
    "import requests, sys, json\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from Bio import SearchIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### web scraping (escolher condição e nº de genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "query= input('escolha o que quer pesquisar: ')\n",
    "def url_get(i):\n",
    "    url_list= [ ]\n",
    "    url = \"https://www.ncbi.nlm.nih.gov/gene/?term={}\".format( query )\n",
    "    url_list.append(url)\n",
    "    return url_list\n",
    "url_get(1)\n",
    "\n",
    "\n",
    "content = []\n",
    "for url in url_get(1):\n",
    "    r = requests.get(url)\n",
    "    content.append(r.content)\n",
    "#print(content)\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Parsing the HTML\n",
    "for c in content:\n",
    "    soup = BeautifulSoup(c, 'html.parser')\n",
    "    a= soup.get_text()\n",
    "    #print (a)\n",
    "\n",
    "existe = re.findall(r\"ID:\\s+\\d*(?=\\D)\", a, re.DOTALL)\n",
    "\n",
    "c= ', '.join(existe)\n",
    "h= c.replace('ID: ','')\n",
    "IDS= h.split(', ')\n",
    "\n",
    "n_genes= IDS[0:int(input('escolha o nº de genes que quer obter (máximo 20): '))]\n",
    "#print(n_genes)\n",
    "\n",
    "if n_genes == ['']:\n",
    "    print (\"Não encontramos resultado para a sua pesquisa\")\n",
    "else:\n",
    "    print (n_genes)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar Links dos genes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def url_get_id(i):\n",
    "    url_list= [ ]\n",
    "    for id in n_genes:\n",
    "        url = \"https://www.ncbi.nlm.nih.gov/nuccore/{}\".format( id )\n",
    "        url_list.append(url)\n",
    "    return url_list\n",
    "url_get_id(n_genes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar ids do ncbi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Ids=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    Ids.append(info.id)\n",
    "    print(info.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar quantidade de cds e a sua localização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ids=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "featcds = [ ]\n",
    "position=0\n",
    "pos=[]\n",
    "for info in records:\n",
    "    #print(info.id)\n",
    "    for i in range(len(info.features)):\n",
    "        if info.features[i].type == \"CDS\":\n",
    "            featcds.append(i)\n",
    "            cds= i\n",
    "            a= str(cds)\n",
    "            print (len(a))\n",
    "            position=i\n",
    "            pos.append(info.features[position].location)\n",
    "            print (pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar organismos (ainda em processo): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Organismos=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    Ids.append(info.id)\n",
    "    print(info.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar Ids de proteinas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pro=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    for i in info.features:\n",
    "        if i.type == \"CDS\":\n",
    "            \n",
    "            pro= str(i.qualifiers[\"protein_id\"])\n",
    "            list_pro.append(pro)\n",
    "div= ', '.join(list_pro)\n",
    "h= div.replace(\"['\",'')\n",
    "hh= h.replace(\"']\",'')\n",
    "ID_PROT= hh.split(', ')\n",
    "print (ID_PROT) # is used below in Uniprot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar Links de proteinas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "ID_PROT\n",
    "def url_get_id_p(a):\n",
    "    url_list_p=[ ]\n",
    "    for id_p in ID_PROT:\n",
    "        url_id_p= \"https://www.uniprot.org/uniprotkb?query={}\".format(id_p)\n",
    "        url_list_p.append(url_id_p)\n",
    "    return url_list_p\n",
    "url_ids_protein=url_get_id_p(ID_PROT)\n",
    "print(url_ids_protein)  # but we don't need to save this links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar id proteina (uniprot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(url, **kwargs):\n",
    "    response = requests.get(url, **kwargs);\n",
    "\n",
    "    if not response.ok:\n",
    "        print(response.text)\n",
    "        response.raise_for_status()\n",
    "        sys.exit()\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final version\n",
    "WEBSITE_API = \"https://rest.uniprot.org\"\n",
    "fields = [\"accession\",\"organism_name\",\"protein_name\",\"cc_subcellular_location\",\"cc_function\", \"sequence\"]\n",
    "\n",
    "def get_field_for_id(ID_PROT, field):\n",
    "    response = get_url(\"{}/uniprotkb/search?query={} AND (reviewed:true)&fields={}&size=1&format=tsv\".format(WEBSITE_API,ID_PROT,field))\n",
    "    return str(response.content)\n",
    "\n",
    "\n",
    "result = {}\n",
    "for field in fields:\n",
    "    result[field] = [get_field_for_id(i, field) for i in ID_PROT]\n",
    "\n",
    "for field, values in result.items():\n",
    "#     print(f\"Results for {field}\")\n",
    "#     print(values)\n",
    "    #regex\n",
    "    for x in values:\n",
    "        entry = re.search(r'b\\'Entry\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL)\n",
    "        organism = re.search(r'b\\'Organism\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL)\n",
    "        function = re.search( r'b\\'Function \\[(CC)\\]\\\\n.{9} (.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "        location = re.search( r'b\\'Subcellular location .{27} (.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "        sequence = re.search(r'b\\'Sequence\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL)\n",
    "        if entry:\n",
    "            e = re.match(r'b\\'Entry\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "            print(e.group(1))\n",
    "        elif organism:\n",
    "            o = re.match(r'b\\'Organism\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "            print(o.group(1))\n",
    "        elif function:\n",
    "            f = re.match(r'b\\'Function .{15} (.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "            print(f.group(1))\n",
    "        elif location:\n",
    "            l = re.match(r'b\\'Subcellular location .{27} (.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "            print(l.group(1))\n",
    "        elif sequence:\n",
    "            s = re.match(r'b\\'Sequence\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL)\n",
    "            print(s.group(1) , len(s.group(1)) )\n",
    "#         else:\n",
    "#             print(\"fail\")\n",
    "#ADD CONDITION FOR EMPY RESULT (MEANS THE ID PROTEIN IS NOT REVIEWED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar seq dos genes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Biopython\n",
    "Ids=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "seq=[]\n",
    "for info in records:\n",
    "    print(info.id)\n",
    "    print(info.seq[0:50],'...',info.seq[-10:])\n",
    "    print()\n",
    "    seq.append(f'{info.seq[0:50]}...{info.seq[-10:]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar gene description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ids=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "description=[]\n",
    "for info in records:\n",
    "    print(info.id)\n",
    "    print(info.description)\n",
    "    description.append(info.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar artigos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ids=[]\n",
    "database = 'PubMed'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"medline\", retmode=\"text\") \n",
    "records = Medline.parse(handle)\n",
    "description=[]\n",
    "for info in records:\n",
    "    print(\"title:\", info.get(\"TI\", \"-\"))\n",
    "    print('authors: ', info.get(\"AU\", \"-\"))\n",
    "    print(\"source:\", info.get(\"SO\", \"-\"))\n",
    "    print(\"affiliation: \", info.get(\"AD\", \"-\") ) # FAZER O IF/ELSE PARA O CASO DE NÃO TER AFFILIATION\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Jorge Gustavo Rocha"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
