{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Blast import NCBIXML \n",
    "from Bio.Blast import NCBIWWW\n",
    "import requests, sys, json\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from Bio import SearchIO\n",
    "from Bio.SwissProt import KeyWList\n",
    "from Bio import SwissProt\n",
    "from Bio import ExPASy\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from Bio.Seq import Seq\n",
    "from Bio import AlignIO\n",
    "from Bio.Align import AlignInfo\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from Bio.Phylo.TreeConstruction import DistanceCalculator\n",
    "from Bio.Phylo.TreeConstruction import DistanceTreeConstructor\n",
    "from Bio import Phylo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### web scraping (escolher condição e nº de genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escolha o que quer pesquisar: irs1\n",
      "escolha o nº de genes que quer obter (máximo 20): 10\n",
      "['3667', '3667', '16367', '25467', '559281', '3077574', '100512686', '538598', '459985', '100607873']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "query= input('escolha o que quer pesquisar: ')\n",
    "def url_get(i):\n",
    "    url_list= [ ]\n",
    "    url = \"https://www.ncbi.nlm.nih.gov/gene/?term={}\".format( query )\n",
    "    url_list.append(url)\n",
    "    return url_list\n",
    "url_get(1)\n",
    "\n",
    "import requests, sys, json\n",
    "content = []\n",
    "for url in url_get(1):\n",
    "    r = requests.get(url)\n",
    "    content.append(r.content)\n",
    "#print(content)\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Parsing the HTML\n",
    "for c in content:\n",
    "    soup = BeautifulSoup(c, 'html.parser')\n",
    "    a= soup.get_text()\n",
    "    #print (a)\n",
    "\n",
    "import re\n",
    "existe = re.findall(r\"ID:\\s+\\d*(?=\\D)\", a, re.DOTALL)\n",
    "\n",
    "c= ', '.join(existe)\n",
    "h= c.replace('ID: ','')\n",
    "IDS= h.split(', ')\n",
    "\n",
    "n_genes= IDS[0:int(input('escolha o nº de genes que quer obter (máximo 20): '))]\n",
    "#print(n_genes)\n",
    "\n",
    "if n_genes == ['']:\n",
    "    print (\"Não encontramos resultado para a sua pesquisa\")\n",
    "else:\n",
    "    print (n_genes)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela \"Gene\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar ids do ncbi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X03907.1\n",
      "AA928418.1\n",
      "AAADR0035516.1\n",
      "L20655.1\n",
      "AAADU0045050.1\n"
     ]
    }
   ],
   "source": [
    "Ids=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    Ids.append(info.id)\n",
    "    print(info.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar Links dos genes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ncbi.nlm.nih.gov/nuccore/X03907.1',\n",
       " 'https://www.ncbi.nlm.nih.gov/nuccore/AA928418.1',\n",
       " 'https://www.ncbi.nlm.nih.gov/nuccore/AAADR0035516.1',\n",
       " 'https://www.ncbi.nlm.nih.gov/nuccore/L20655.1',\n",
       " 'https://www.ncbi.nlm.nih.gov/nuccore/AAADU0045050.1']"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "def url_get_id(i):\n",
    "    url_list= [ ]\n",
    "    for id in i:\n",
    "        url = \"https://www.ncbi.nlm.nih.gov/nuccore/{}\".format( id )\n",
    "        url_list.append(url)\n",
    "    return url_list\n",
    "url_get_id(Ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar organismos: (novo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organismos\n",
    "\n",
    "Organismos=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    Organismos.append(info.annotations['organism'])\n",
    "print(Organismos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar seq dos genes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Biopython\n",
    "Ids=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "seq=[]\n",
    "for info in records:\n",
    "    print(info.id)\n",
    "    print(info.seq[0:50],'...',info.seq[-10:])\n",
    "    print()\n",
    "    seq.append(f'{info.seq[0:50]}...{info.seq[-10:]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar % de Alanina:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adenina=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "seq=[]\n",
    "for info in records:\n",
    "    c=info.seq\n",
    "    count= c.count('A')\n",
    "    perc= (count/len(c)*100)\n",
    "    Adenina.append(perc)\n",
    "print (Adenina)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar % de Citosina:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Citosina=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "seq=[]\n",
    "for info in records:\n",
    "    c=info.seq\n",
    "    count= c.count('C')\n",
    "    perc= (count/len(c)*100)\n",
    "    Citosina.append(perc)\n",
    "print (Citosina)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar % de Guanina:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Guanina=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "seq=[]\n",
    "for info in records:\n",
    "    c=info.seq\n",
    "    count= c.count('G')\n",
    "    perc= (count/len(c)*100)\n",
    "    Guanina.append(perc)\n",
    "print (Guanina)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar % de Timina:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Timina=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "seq=[]\n",
    "for info in records:\n",
    "    c=info.seq\n",
    "    count= c.count('T')\n",
    "    perc= (count/len(c)*100)\n",
    "    Timina.append(perc)\n",
    "print (Timina)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar gene description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ids=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "description=[]\n",
    "for info in records:\n",
    "    print(info.id)\n",
    "    print(info.description)\n",
    "    description.append(info.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    data.append(info.annotations['date'])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar tamanho:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "tam=[]\n",
    "for info in records:\n",
    "    tam.append(len(info.seq))\n",
    "\n",
    "print(tam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela \"CDS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar quantidade de cds e a sua localização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ids=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "featcds = [ ]\n",
    "position=0\n",
    "pos=[]\n",
    "for info in records:\n",
    "    for i in range(len(info.features)):\n",
    "        if info.features[i].type == \"CDS\":\n",
    "            cds= i\n",
    "            a= str(cds)\n",
    "            b= len(a)\n",
    "            print (b)\n",
    "            featcds.append(b)\n",
    "            #position=i\n",
    "            #pos.append(info.features[position].location)\n",
    "            #print (pos)\n",
    "    #for h in info.features:\n",
    "        #if h.type[\"CDS\"] == none:\n",
    "            #featcds.append(\"sem resultados\")\n",
    "print(teste)     \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela \"Uniprot\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar Ids de proteinas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pro=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    for i in info.features:\n",
    "        if i.type == \"CDS\":\n",
    "            \n",
    "            pro= str(i.qualifiers[\"protein_id\"])\n",
    "            list_pro.append(pro)\n",
    "            \n",
    "div= ', '.join(list_pro)\n",
    "h= div.replace(\"['\",'')\n",
    "hh= h.replace(\"']\",'')\n",
    "ID_PROT= hh.split(', ')\n",
    "print (ID_PROT) # is used below in Uniprot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar Links de proteinas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "ID_PROT\n",
    "def url_get_id_p(a):\n",
    "    url_list_p=[ ]\n",
    "    for id_p in ID_PROT:\n",
    "        url_id_p= \"https://www.uniprot.org/uniprotkb?query={}\".format(id_p)\n",
    "        url_list_p.append(url_id_p)\n",
    "    return url_list_p\n",
    "url_ids_protein=url_get_id_p(ID_PROT)\n",
    "print(url_ids_protein)  # but we don't need to save this links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar id proteina (uniprot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(url, **kwargs):\n",
    "    response = requests.get(url, **kwargs);\n",
    "\n",
    "    if not response.ok:\n",
    "        print(response.text)\n",
    "        response.raise_for_status()\n",
    "        sys.exit()\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final version\n",
    "WEBSITE_API = \"https://rest.uniprot.org\"\n",
    "fields = [\"accession\",\"organism_name\",\"protein_name\",\"cc_subcellular_location\",\"cc_function\", \"sequence\"]\n",
    "\n",
    "def get_field_for_id(ID_PROT, field):\n",
    "    response = get_url(\"{}/uniprotkb/search?query={} AND (reviewed:true)&fields={}&size=1&format=tsv\".format(WEBSITE_API,ID_PROT,field))\n",
    "    return str(response.content)\n",
    "\n",
    "\n",
    "result = {}\n",
    "for field in fields:\n",
    "    result[field] = [get_field_for_id(i, field) for i in ID_PROT]\n",
    "\n",
    "for field, values in result.items():\n",
    "#     print(f\"Results for {field}\")\n",
    "#     print(values)\n",
    "    #regex\n",
    "    for x in values:\n",
    "        entry = re.search(r'b\\'Entry\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL)\n",
    "        organism = re.search(r'b\\'Organism\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL)\n",
    "        function = re.search( r'b\\'Function \\[(CC)\\]\\\\n.{9} (.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "        location = re.search( r'b\\'Subcellular location .{27} (.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "        sequence = re.search(r'b\\'Sequence\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL)\n",
    "        if entry:\n",
    "            e = re.match(r'b\\'Entry\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "            print(e.group(1))\n",
    "        elif organism:\n",
    "            o = re.match(r'b\\'Organism\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "            print(o.group(1))\n",
    "        elif function:\n",
    "            f = re.match(r'b\\'Function .{15} (.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "            print(f.group(1))\n",
    "        elif location:\n",
    "            l = re.match(r'b\\'Subcellular location .{27} (.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "            print(l.group(1))\n",
    "        elif sequence:\n",
    "            s = re.match(r'b\\'Sequence\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL)\n",
    "            print(s.group(1) , len(s.group(1)) )\n",
    "#         else:\n",
    "#             print(\"fail\")\n",
    "#ADD CONDITION FOR EMPY RESULT (MEANS THE ID PROTEIN IS NOT REVIEWED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela \"Pubmed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar id de artigos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'X03907.1': ['3012462'], 'AA928418.1': [], 'AAADR0035516.1': ['14663149', '14960301', '16141072', '16141073', '16645617'], 'L20655.1': ['8116255'], 'AAADU0045050.1': ['14663149', '14960301', '16141072', '16141073', '16645617']}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "content_id = []\n",
    "for url in url_get_id(Ids):\n",
    "    r_id = requests.get(url)\n",
    "    content_id.append(r_id.content)\n",
    "    \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "listas=[]\n",
    "# Parsing the HTML\n",
    "for c in content_id:\n",
    "    soup_id = BeautifulSoup(c, 'html.parser')\n",
    "\n",
    "    # Procurar um tag meta com um determinado atributo\n",
    "    lines = soup_id.find_all('meta', {'name':\"ncbi_uidlist\"} )\n",
    "\n",
    "    id = \"\"\n",
    "    url = \"\"\n",
    "    for line in lines:\n",
    "        #print(line)\n",
    "        #if 'name' in line.attrs:\n",
    "        #    print(line.attrs['name'])\n",
    "        if 'content' in line.attrs:\n",
    "            # print(line.attrs['content'])\t\t\n",
    "            id = line.attrs['content']\n",
    "\n",
    "    if id:\n",
    "        url = \"https://www.ncbi.nlm.nih.gov/sviewer/viewer.fcgi?id={}&db=nuccore&report=genbank&conwithfeat=on&hide-cdd=on&retmode=text&maxdownloadsize=5000000\".format(id)\n",
    "\n",
    "    r2 = requests.get(url)\n",
    "    r4= r2.content.decode('utf-8')\n",
    "    #r4= str(r2.content)\n",
    "    listas.append(r4)\n",
    "cc= ', '.join(listas)\n",
    "er= cc.replace('//','')\n",
    "final= er.split(', ')\n",
    "#print (er)\n",
    "\n",
    "output_dict = {}\n",
    "for x in final:\n",
    "    version = re.search(r'VERSION\\s+(.*?)\\s', x)\n",
    "    pubmed = re.search(r'PUBMED\\s+(.*?)\\s', x)\n",
    "    if version:\n",
    "#         print(version.group(1))\n",
    "        versionf=version.group(1)\n",
    "        output_dict.setdefault(version.group(1), [])\n",
    "    if pubmed:\n",
    "#         print(pubmed.group(1))\n",
    "        output_dict[versionf].append(pubmed.group(1))\n",
    "#     else:\n",
    "       # output_dict[version.group(1)].append(\"N/A\")\n",
    "\n",
    "print(output_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_list = []\n",
    "values_list = []\n",
    "for key, vals in output_dict.items():\n",
    "    if vals:\n",
    "        for val in vals:\n",
    "            keys_list.append(key)\n",
    "            values_list.append(val)\n",
    "    else:\n",
    "        keys_list.append(key)\n",
    "        values_list.append(\"N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X03907.1', 'AA928418.1', 'AAADR0035516.1', 'AAADR0035516.1', 'AAADR0035516.1', 'AAADR0035516.1', 'AAADR0035516.1', 'L20655.1', 'AAADU0045050.1', 'AAADU0045050.1', 'AAADU0045050.1', 'AAADU0045050.1', 'AAADU0045050.1']\n"
     ]
    }
   ],
   "source": [
    "print(keys_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3012462', 'N/A', '14663149', '14960301', '16141072', '16141073', '16645617', '8116255', '14663149', '14960301', '16141072', '16141073', '16645617']\n"
     ]
    }
   ],
   "source": [
    "print(values_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_ids_pubmed = [val for key, vals in output_dict.items() for val in vals]\n",
    "so_ids_ncbi = list(output_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3012462', '14663149', '14960301', '16141072', '16141073', '16645617', '8116255', '14663149', '14960301', '16141072', '16141073', '16645617']\n"
     ]
    }
   ],
   "source": [
    "print(so_ids_pubmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X03907.1', 'AA928418.1', 'AAADR0035516.1', 'L20655.1', 'AAADU0045050.1']\n"
     ]
    }
   ],
   "source": [
    "print(so_ids_ncbi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#lista_final=[]\n",
    "#for x in final:\n",
    "    #Pub = re.search(r'VERSION\\s+.*?(?=\\s)|(PUBMED\\s+.*?(?=\\s))', x, re.DOTALL)\n",
    "    #if Pub:\n",
    "        #print (Pub.group(0))\n",
    "        #lista_final.append(Pub.group(0))\n",
    "   \n",
    "    \n",
    "#print(lista_final)\n",
    "#limpar= \"' \".join(lista_final)\n",
    "#id_pubmedES= limpar.split('VERSION     ')     ######## criar dicionário aqui!!!!\n",
    "#sem_virgulas= ', '.join(id_pubmedES)\n",
    "#m= sem_virgulas[2:-1]\n",
    "#limpo= m.replace('PUBMED   ','')\n",
    "#limpinho= limpo.replace(\"'\" ,'')\n",
    "#id_pu= limpinho.split(' , ')\n",
    "#print(id_pu)\n",
    "\n",
    "#lista_final_final=[]\n",
    "#for x in id_pu:\n",
    "    #if x.count(' ') == 0:\n",
    "        #rep= x\n",
    "\n",
    "#replace=\",\".join(id_pu)\n",
    "#NA= replace.replace(f'{rep}','RESULTADO: N/A')\n",
    "#id_FINAL= NA.split(',')\n",
    "#print(id_FINAL)\n",
    "\n",
    "#for h in id_FINAL:\n",
    "    #FINA = re.search(r'\\s.*?(?=$)', h, re.DOTALL)\n",
    "    #if FINA:\n",
    "        #print (FINA.group(0))\n",
    "        #lista_final_final.append([FINA.group(0)])\n",
    "    #else:\n",
    "        #lista_final_final.append([])\n",
    "\n",
    "#for i in lista_final_final:\n",
    "    #print (i)\n",
    "#SE=\",\".join(lista_final_final[0])\n",
    "#id_FI= SE.split(' ')\n",
    "#print(lista_final_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINAL\n",
    "#result_dict = {}\n",
    "#database = 'nucleotide'\n",
    "#email= 'rodrigoce9@gmail.com'\n",
    "#idlist=Ids\n",
    "# idlist= Ids.remove('U49845')\n",
    "#for ids in idlist:\n",
    "    #list_pro=[]\n",
    "    #handle = Entrez.efetch(db=database, id=ids, rettype=\"gb\") \n",
    "   #records = list(SeqIO.parse(handle,\"gb\"))\n",
    "    #handle.close()\n",
    "    #for info in records:\n",
    "        #list_pro.append(info.id)\n",
    "        #for i in info.features:\n",
    "            #if i.type == \"CDS\":\n",
    "                #pro= str(i.qualifiers[\"protein_id\"])\n",
    "                #list_pro.append(pro)\n",
    "        #if len(list_pro)==1: #if no protein_id was found\n",
    "            #result_dict[info.id] = \"N/A\"\n",
    "        #else:\n",
    "            #list_pro = [x.replace(\"['\",'').replace(\"']\",'') for x in list_pro]\n",
    "            #result_dict[info.id] = ', '.join(list_pro[1:])\n",
    "#print(result_dict)\n",
    "#key: id_genebank; values: id_Uniprot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar artigos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affiliation:  N/A\n",
      "affiliation:  ['Laboratory for Genome Exploration Research Group, RIKEN Genomic Sciences Center, Yokohama Institute 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, Kanagawa 230-0045, Japan.']\n",
      "affiliation:  ['Genome Science Laboratory, RIKEN, Wako Main Campus, Hirosawa 2-1, Wako, Saitama 351-0198, Japan.']\n",
      "affiliation:  N/A\n",
      "affiliation:  ['Laboratory for Genome Exploration Research Group, RIKEN Genomic Sciences Centre (GSC), RIKEN Yokohama Institute, 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, 230-0045, Japan.']\n",
      "affiliation:  ['Genome Exploration Research Group, RIKEN Genomic Sciences Center, RIKEN Yokohama Institute, 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, Kanagawa, 230-0045, Japan.']\n",
      "affiliation:  ['Laboratory of Central Nervous System Studies, National Institute of Neurological Disorders and Stroke, National Institutes of Health, Bethesda, Maryland 20892.']\n",
      "affiliation:  ['Laboratory for Genome Exploration Research Group, RIKEN Genomic Sciences Center, Yokohama Institute 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, Kanagawa 230-0045, Japan.']\n",
      "affiliation:  ['Genome Science Laboratory, RIKEN, Wako Main Campus, Hirosawa 2-1, Wako, Saitama 351-0198, Japan.']\n",
      "affiliation:  N/A\n",
      "affiliation:  ['Laboratory for Genome Exploration Research Group, RIKEN Genomic Sciences Centre (GSC), RIKEN Yokohama Institute, 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, 230-0045, Japan.']\n",
      "affiliation:  ['Genome Exploration Research Group, RIKEN Genomic Sciences Center, RIKEN Yokohama Institute, 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, Kanagawa, 230-0045, Japan.']\n"
     ]
    }
   ],
   "source": [
    "titles= []\n",
    "authors=[]\n",
    "source=[]\n",
    "affiliation=[]\n",
    "database = 'PubMed'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= values_list\n",
    "counter = 0\n",
    "for i in idlist:\n",
    "    if i!= \"N/A\":\n",
    "        handle = Entrez.efetch(db=database, id=i, rettype=\"medline\", retmode=\"text\") \n",
    "        records = Medline.parse(handle)\n",
    "        for info in records:\n",
    "            #print(f'id: {i}')\n",
    "            #print(\"title:\", info.get(\"TI\", \"-\"))\n",
    "            titles.append(info.get(\"TI\", \"-\"))\n",
    "            #print('authors: ', info.get(\"AU\", \"-\"))\n",
    "            authors_string = info.get(\"AU\", \"-\")\n",
    "            if len(authors_string) > 5:\n",
    "                authors_h = authors_string[:5]\n",
    "                authors.append(authors_h)\n",
    "            #print(\"source:\", info.get(\"SO\", \"-\"))\n",
    "            source.append(info.get(\"SO\", \"-\"))\n",
    "            #print(\"affiliation: \", info.get(\"AD\", \"N/A\") ) # FAZER O IF/ELSE PARA O CASO DE NÃO TER AFFILIATION\n",
    "            affiliation_string= info.get(\"AD\", \"N/A\")\n",
    "            if len(affiliation_string) > 5:\n",
    "                affiliation_h = affiliation_string[:5]\n",
    "                affiliation.append(affiliation_h)\n",
    "            #print()\n",
    "            counter += 1\n",
    "    else:\n",
    "        #print(f'id: {i} - N/A')\n",
    "        titles.append(\"N/A\")\n",
    "        authors.append(\"N/A\")\n",
    "        source.append(\"N/A\")\n",
    "        affiliation.append(\"N/A\")\n",
    "        #print()\n",
    "        counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Structure and expression of three light-harvesting chlorophyll a/b-binding protein genes in Arabidopsis thaliana.', 'N/A', 'Cap analysis gene expression for high-throughput analysis of transcriptional starting point and identification of promoter usage.', 'Absolute expression values for mouse transcripts: re-annotation of the READ expression database by the use of CAGE and EST sequence tags.', 'The transcriptional landscape of the mammalian genome.', 'Antisense transcription in the mammalian transcriptome.', 'Genome-wide analysis of mammalian promoter architecture and evolution.', 'Genetic analysis and molecular phylogeny of simian T-cell lymphotropic virus type I: evidence for independent virus evolution in Asia and Africa.', 'Cap analysis gene expression for high-throughput analysis of transcriptional starting point and identification of promoter usage.', 'Absolute expression values for mouse transcripts: re-annotation of the READ expression database by the use of CAGE and EST sequence tags.', 'The transcriptional landscape of the mammalian genome.', 'Antisense transcription in the mammalian transcriptome.', 'Genome-wide analysis of mammalian promoter architecture and evolution.']\n"
     ]
    }
   ],
   "source": [
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [ [title] for title in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Nucleic Acids Res. 1986 May 27;14(10):4051-64. doi: 10.1093/nar/14.10.4051.', 'N/A', 'Proc Natl Acad Sci U S A. 2003 Dec 23;100(26):15776-81. doi: 10.1073/pnas.2136655100. Epub 2003 Dec 8.', 'FEBS Lett. 2004 Feb 13;559(1-3):22-6. doi: 10.1016/S0014-5793(04)00018-3.', 'Science. 2005 Sep 2;309(5740):1559-63. doi: 10.1126/science.1112014.', 'Science. 2005 Sep 2;309(5740):1564-6. doi: 10.1126/science.1112009.', 'Nat Genet. 2006 Jun;38(6):626-35. doi: 10.1038/ng1789. Epub 2006 Apr 28.', 'Virology. 1994 Feb 15;199(1):56-66. doi: 10.1006/viro.1994.1097.', 'Proc Natl Acad Sci U S A. 2003 Dec 23;100(26):15776-81. doi: 10.1073/pnas.2136655100. Epub 2003 Dec 8.', 'FEBS Lett. 2004 Feb 13;559(1-3):22-6. doi: 10.1016/S0014-5793(04)00018-3.', 'Science. 2005 Sep 2;309(5740):1559-63. doi: 10.1126/science.1112014.', 'Science. 2005 Sep 2;309(5740):1564-6. doi: 10.1126/science.1112009.', 'Nat Genet. 2006 Jun;38(6):626-35. doi: 10.1038/ng1789. Epub 2006 Apr 28.']\n"
     ]
    }
   ],
   "source": [
    "print (source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10.1093/nar/14.10.4051.', 'N/A', '10.1073/pnas.2136655100. Epub 2003 Dec 8.', '10.1016/S0014-5793(04)00018-3.', '10.1126/science.1112014.', '10.1126/science.1112009.', '10.1038/ng1789. Epub 2006 Apr 28.', '10.1006/viro.1994.1097.', '10.1073/pnas.2136655100. Epub 2003 Dec 8.', '10.1016/S0014-5793(04)00018-3.', '10.1126/science.1112014.', '10.1126/science.1112009.', '10.1038/ng1789. Epub 2006 Apr 28.']\n"
     ]
    }
   ],
   "source": [
    "doi_list = []\n",
    "for x in source:\n",
    "    match = re.search(\"doi: (.*)\", x)\n",
    "    if match:\n",
    "        doi_list.append(match.group(1))\n",
    "    else:\n",
    "        doi_list.append(\"N/A\")\n",
    "        \n",
    "print(doi_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "output_dict_reverse = defaultdict(list)\n",
    "for x in final:\n",
    "    version = re.search(r'VERSION\\s+(.*?)\\s', x)\n",
    "    pubmed = re.search(r'PUBMED\\s+(.*?)\\s', x)\n",
    "    if pubmed:\n",
    "        output_dict_reverse[pubmed.group(1)].append(version.group(1) if version else \"N/A\")\n",
    "    elif version:\n",
    "        output_dict_reverse[version.group(1)].append(\"N/A\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'X03907.1': ['N/A'], '3012462': ['N/A'], 'AA928418.1': ['N/A'], 'AAADR0035516.1': ['N/A'], '14663149': ['N/A', 'N/A'], '14960301': ['N/A', 'N/A'], '16141072': ['N/A', 'N/A'], '16141073': ['N/A', 'N/A'], '16645617': ['N/A', 'N/A'], 'L20655.1': ['N/A'], '8116255': ['N/A'], 'AAADU0045050.1': ['N/A']})\n"
     ]
    }
   ],
   "source": [
    "print(output_dict_reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Jorge Gustavo Rocha"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
