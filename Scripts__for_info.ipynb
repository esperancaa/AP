{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Blast import NCBIXML \n",
    "from Bio.Blast import NCBIWWW\n",
    "import requests, sys, json\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from Bio import SearchIO\n",
    "from Bio.SwissProt import KeyWList\n",
    "from Bio import SwissProt\n",
    "from Bio import ExPASy\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from Bio.Seq import Seq\n",
    "from Bio import AlignIO\n",
    "from Bio.Align import AlignInfo\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from Bio.Phylo.TreeConstruction import DistanceCalculator\n",
    "from Bio.Phylo.TreeConstruction import DistanceTreeConstructor\n",
    "from Bio import Phylo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### web scraping (escolher condição e nº de genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "escolha o que quer pesquisar: irs1\n",
      "escolha o nº de genes que quer obter (máximo 20): 10\n",
      "['3667', '3667', '16367', '25467', '559281', '3077574', '100512686', '538598', '459985', '100607873']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "query= input('escolha o que quer pesquisar: ')\n",
    "def url_get(i):\n",
    "    url_list= [ ]\n",
    "    url = \"https://www.ncbi.nlm.nih.gov/gene/?term={}\".format( query )\n",
    "    url_list.append(url)\n",
    "    return url_list\n",
    "url_get(1)\n",
    "\n",
    "import requests, sys, json\n",
    "content = []\n",
    "for url in url_get(1):\n",
    "    r = requests.get(url)\n",
    "    content.append(r.content)\n",
    "#print(content)\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Parsing the HTML\n",
    "for c in content:\n",
    "    soup = BeautifulSoup(c, 'html.parser')\n",
    "    a= soup.get_text()\n",
    "    #print (a)\n",
    "\n",
    "import re\n",
    "existe = re.findall(r\"ID:\\s+\\d*(?=\\D)\", a, re.DOTALL)\n",
    "\n",
    "c= ', '.join(existe)\n",
    "h= c.replace('ID: ','')\n",
    "IDS= h.split(', ')\n",
    "\n",
    "n_genes= IDS[0:int(input('escolha o nº de genes que quer obter (máximo 20): '))]\n",
    "#print(n_genes)\n",
    "\n",
    "if n_genes == ['']:\n",
    "    print (\"Não encontramos resultado para a sua pesquisa\")\n",
    "else:\n",
    "    print (n_genes)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela \"Gene\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar ids do ncbi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rodri\\anaconda3\\lib\\site-packages\\Bio\\Entrez\\__init__.py:658: UserWarning: \n",
      "Email address is not specified.\n",
      "\n",
      "To make use of NCBI's E-utilities, NCBI requires you to specify your\n",
      "email address with each request.  As an example, if your email address\n",
      "is A.N.Other@example.com, you can specify it as follows:\n",
      "   from Bio import Entrez\n",
      "   Entrez.email = 'A.N.Other@example.com'\n",
      "In case of excessive usage of the E-utilities, NCBI will attempt to contact\n",
      "a user at the email address provided before blocking access to the\n",
      "E-utilities.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X03907.1\n",
      "AA928418.1\n",
      "AAADR0035516.1\n",
      "L20655.1\n",
      "AAADU0045050.1\n"
     ]
    }
   ],
   "source": [
    "Ids=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    Ids.append(info.id)\n",
    "    print(info.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar Links dos genes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.ncbi.nlm.nih.gov/nuccore/X03907.1',\n",
       " 'https://www.ncbi.nlm.nih.gov/nuccore/AA928418.1',\n",
       " 'https://www.ncbi.nlm.nih.gov/nuccore/AAADR0035516.1',\n",
       " 'https://www.ncbi.nlm.nih.gov/nuccore/L20655.1',\n",
       " 'https://www.ncbi.nlm.nih.gov/nuccore/AAADU0045050.1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "def url_get_id(i):\n",
    "    url_list= [ ]\n",
    "    for id in i:\n",
    "        url = \"https://www.ncbi.nlm.nih.gov/nuccore/{}\".format( id )\n",
    "        url_list.append(url)\n",
    "    return url_list\n",
    "url_get_id(Ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar organismos: (novo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#organismos\n",
    "\n",
    "Organismos=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    Organismos.append(info.annotations['organism'])\n",
    "print(Organismos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar seq dos genes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Biopython\n",
    "Ids=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "seq=[]\n",
    "for info in records:\n",
    "    print(info.id)\n",
    "    print(info.seq[0:50],'...',info.seq[-10:])\n",
    "    print()\n",
    "    seq.append(f'{info.seq[0:50]}...{info.seq[-10:]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar % de Alanina:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Adenina=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "seq=[]\n",
    "for info in records:\n",
    "    c=info.seq\n",
    "    count= c.count('A')\n",
    "    perc= (count/len(c)*100)\n",
    "    Adenina.append(perc)\n",
    "print (Adenina)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar % de Citosina:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Citosina=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "seq=[]\n",
    "for info in records:\n",
    "    c=info.seq\n",
    "    count= c.count('C')\n",
    "    perc= (count/len(c)*100)\n",
    "    Citosina.append(perc)\n",
    "print (Citosina)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar % de Guanina:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Guanina=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "seq=[]\n",
    "for info in records:\n",
    "    c=info.seq\n",
    "    count= c.count('G')\n",
    "    perc= (count/len(c)*100)\n",
    "    Guanina.append(perc)\n",
    "print (Guanina)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar % de Timina:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Timina=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "seq=[]\n",
    "for info in records:\n",
    "    c=info.seq\n",
    "    count= c.count('T')\n",
    "    perc= (count/len(c)*100)\n",
    "    Timina.append(perc)\n",
    "print (Timina)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar gene description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ids=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "description=[]\n",
    "for info in records:\n",
    "    print(info.id)\n",
    "    print(info.description)\n",
    "    description.append(info.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    data.append(info.annotations['date'])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar tamanho:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "tam=[]\n",
    "for info in records:\n",
    "    tam.append(len(info.seq))\n",
    "\n",
    "print(tam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela \"CDS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar quantidade de cds e a sua localização:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ids=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "featcds = [ ]\n",
    "position=0\n",
    "pos=[]\n",
    "for info in records:\n",
    "    for i in range(len(info.features)):\n",
    "        if info.features[i].type == \"CDS\":\n",
    "            cds= i\n",
    "            a= str(cds)\n",
    "            b= len(a)\n",
    "            print (b)\n",
    "            featcds.append(b)\n",
    "            #position=i\n",
    "            #pos.append(info.features[position].location)\n",
    "            #print (pos)\n",
    "    #for h in info.features:\n",
    "        #if h.type[\"CDS\"] == none:\n",
    "            #featcds.append(\"sem resultados\")\n",
    "print(teste)     \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela \"Uniprot\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar Ids de proteinas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pro=[]\n",
    "database = 'nucleotide'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= n_genes\n",
    "handle = Entrez.efetch(db=database, id=idlist, rettype=\"gb\") \n",
    "records = list(SeqIO.parse(handle,\"gb\"))\n",
    "handle.close()\n",
    "for info in records:\n",
    "    for i in info.features:\n",
    "        if i.type == \"CDS\":\n",
    "            \n",
    "            pro= str(i.qualifiers[\"protein_id\"])\n",
    "            list_pro.append(pro)\n",
    "            \n",
    "div= ', '.join(list_pro)\n",
    "h= div.replace(\"['\",'')\n",
    "hh= h.replace(\"']\",'')\n",
    "ID_PROT= hh.split(', ')\n",
    "print (ID_PROT) # is used below in Uniprot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar Links de proteinas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "ID_PROT\n",
    "def url_get_id_p(a):\n",
    "    url_list_p=[ ]\n",
    "    for id_p in ID_PROT:\n",
    "        url_id_p= \"https://www.uniprot.org/uniprotkb?query={}\".format(id_p)\n",
    "        url_list_p.append(url_id_p)\n",
    "    return url_list_p\n",
    "url_ids_protein=url_get_id_p(ID_PROT)\n",
    "print(url_ids_protein)  # but we don't need to save this links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar id proteina (uniprot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(url, **kwargs):\n",
    "    response = requests.get(url, **kwargs);\n",
    "\n",
    "    if not response.ok:\n",
    "        print(response.text)\n",
    "        response.raise_for_status()\n",
    "        sys.exit()\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final version\n",
    "WEBSITE_API = \"https://rest.uniprot.org\"\n",
    "fields = [\"accession\",\"organism_name\",\"protein_name\",\"cc_subcellular_location\",\"cc_function\", \"sequence\"]\n",
    "\n",
    "def get_field_for_id(ID_PROT, field):\n",
    "    response = get_url(\"{}/uniprotkb/search?query={} AND (reviewed:true)&fields={}&size=1&format=tsv\".format(WEBSITE_API,ID_PROT,field))\n",
    "    return str(response.content)\n",
    "\n",
    "\n",
    "result = {}\n",
    "for field in fields:\n",
    "    result[field] = [get_field_for_id(i, field) for i in ID_PROT]\n",
    "\n",
    "for field, values in result.items():\n",
    "#     print(f\"Results for {field}\")\n",
    "#     print(values)\n",
    "    #regex\n",
    "    for x in values:\n",
    "        entry = re.search(r'b\\'Entry\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL)\n",
    "        organism = re.search(r'b\\'Organism\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL)\n",
    "        function = re.search( r'b\\'Function \\[(CC)\\]\\\\n.{9} (.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "        location = re.search( r'b\\'Subcellular location .{27} (.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "        sequence = re.search(r'b\\'Sequence\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL)\n",
    "        if entry:\n",
    "            e = re.match(r'b\\'Entry\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "            print(e.group(1))\n",
    "        elif organism:\n",
    "            o = re.match(r'b\\'Organism\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "            print(o.group(1))\n",
    "        elif function:\n",
    "            f = re.match(r'b\\'Function .{15} (.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "            print(f.group(1))\n",
    "        elif location:\n",
    "            l = re.match(r'b\\'Subcellular location .{27} (.+?(?=\\\\n\\'))', x, re.DOTALL )\n",
    "            print(l.group(1))\n",
    "        elif sequence:\n",
    "            s = re.match(r'b\\'Sequence\\\\n(.+?(?=\\\\n\\'))', x, re.DOTALL)\n",
    "            print(s.group(1) , len(s.group(1)) )\n",
    "#         else:\n",
    "#             print(\"fail\")\n",
    "#ADD CONDITION FOR EMPY RESULT (MEANS THE ID PROTEIN IS NOT REVIEWED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabela \"Pubmed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar id de artigos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'X03907.1': ['3012462'], 'AA928418.1': [], 'AAADR0035516.1': ['14663149', '14960301', '16141072', '16141073', '16645617'], 'L20655.1': ['8116255'], 'AAADU0045050.1': ['14663149', '14960301', '16141072', '16141073', '16645617']}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "content_id = []\n",
    "for url in url_get_id(Ids):\n",
    "    r_id = requests.get(url)\n",
    "    content_id.append(r_id.content)\n",
    "    \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "listas=[]\n",
    "# Parsing the HTML\n",
    "for c in content_id:\n",
    "    soup_id = BeautifulSoup(c, 'html.parser')\n",
    "\n",
    "    # Procurar um tag meta com um determinado atributo\n",
    "    lines = soup_id.find_all('meta', {'name':\"ncbi_uidlist\"} )\n",
    "\n",
    "    id = \"\"\n",
    "    url = \"\"\n",
    "    for line in lines:\n",
    "        #print(line)\n",
    "        #if 'name' in line.attrs:\n",
    "        #    print(line.attrs['name'])\n",
    "        if 'content' in line.attrs:\n",
    "            # print(line.attrs['content'])\t\t\n",
    "            id = line.attrs['content']\n",
    "\n",
    "    if id:\n",
    "        url = \"https://www.ncbi.nlm.nih.gov/sviewer/viewer.fcgi?id={}&db=nuccore&report=genbank&conwithfeat=on&hide-cdd=on&retmode=text&maxdownloadsize=5000000\".format(id)\n",
    "\n",
    "    r2 = requests.get(url)\n",
    "    r4= r2.content.decode('utf-8')\n",
    "    #r4= str(r2.content)\n",
    "    listas.append(r4)\n",
    "cc= ', '.join(listas)\n",
    "er= cc.replace('//','')\n",
    "final= er.split(', ')\n",
    "#print (er)\n",
    "\n",
    "output_dict = {}\n",
    "for x in final:\n",
    "    version = re.search(r'VERSION\\s+(.*?)\\s', x)\n",
    "    pubmed = re.search(r'PUBMED\\s+(.*?)\\s', x)\n",
    "    if version:\n",
    "#         print(version.group(1))\n",
    "        versionf=version.group(1)\n",
    "        output_dict.setdefault(version.group(1), [])\n",
    "    if pubmed:\n",
    "#         print(pubmed.group(1))\n",
    "        output_dict[versionf].append(pubmed.group(1))\n",
    "#     else:\n",
    "       # output_dict[version.group(1)].append(\"N/A\")\n",
    "\n",
    "print(output_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys_list = []\n",
    "values_list = []\n",
    "for key, vals in output_dict.items():\n",
    "    if vals:\n",
    "        for val in vals:\n",
    "            keys_list.append(key)\n",
    "            values_list.append(val)\n",
    "    else:\n",
    "        keys_list.append(key)\n",
    "        values_list.append(\"N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X03907.1', 'AA928418.1', 'AAADR0035516.1', 'AAADR0035516.1', 'AAADR0035516.1', 'AAADR0035516.1', 'AAADR0035516.1', 'L20655.1', 'AAADU0045050.1', 'AAADU0045050.1', 'AAADU0045050.1', 'AAADU0045050.1', 'AAADU0045050.1']\n"
     ]
    }
   ],
   "source": [
    "print(keys_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3012462', 'N/A', '14663149', '14960301', '16141072', '16141073', '16645617', '8116255', '14663149', '14960301', '16141072', '16141073', '16645617']\n"
     ]
    }
   ],
   "source": [
    "print(values_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3012462', 'N/A', '14663149', '14960301', '16141072', '16141073', '16645617', '8116255']\n"
     ]
    }
   ],
   "source": [
    "new_list_ = []\n",
    "seen = set()\n",
    "for item in values_list:\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        new_list_.append(item)\n",
    "print(new_list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3012462', '14663149', '16645617', '8116255', 'N/A', '16141072', '16141073', '14960301'}\n"
     ]
    }
   ],
   "source": [
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "number_map = {}\n",
    "next_number = 1\n",
    "output = []\n",
    "for number in values_list:\n",
    "    if number not in number_map:\n",
    "        number_map[number] = next_number\n",
    "        next_number += 1\n",
    "    output.append(number_map[number])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "so_ids_pubmed = [val for key, vals in output_dict.items() for val in vals]\n",
    "so_ids_ncbi = list(output_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "A= set(so_ids_pubmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3012462', '14663149', '16645617', '8116255', '16141073', '16141072', '14960301'}\n"
     ]
    }
   ],
   "source": [
    "print (A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['X03907.1', 'AA928418.1', 'AAADR0035516.1', 'L20655.1', 'AAADU0045050.1']\n"
     ]
    }
   ],
   "source": [
    "print(so_ids_ncbi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#lista_final=[]\n",
    "#for x in final:\n",
    "    #Pub = re.search(r'VERSION\\s+.*?(?=\\s)|(PUBMED\\s+.*?(?=\\s))', x, re.DOTALL)\n",
    "    #if Pub:\n",
    "        #print (Pub.group(0))\n",
    "        #lista_final.append(Pub.group(0))\n",
    "   \n",
    "    \n",
    "#print(lista_final)\n",
    "#limpar= \"' \".join(lista_final)\n",
    "#id_pubmedES= limpar.split('VERSION     ')     ######## criar dicionário aqui!!!!\n",
    "#sem_virgulas= ', '.join(id_pubmedES)\n",
    "#m= sem_virgulas[2:-1]\n",
    "#limpo= m.replace('PUBMED   ','')\n",
    "#limpinho= limpo.replace(\"'\" ,'')\n",
    "#id_pu= limpinho.split(' , ')\n",
    "#print(id_pu)\n",
    "\n",
    "#lista_final_final=[]\n",
    "#for x in id_pu:\n",
    "    #if x.count(' ') == 0:\n",
    "        #rep= x\n",
    "\n",
    "#replace=\",\".join(id_pu)\n",
    "#NA= replace.replace(f'{rep}','RESULTADO: N/A')\n",
    "#id_FINAL= NA.split(',')\n",
    "#print(id_FINAL)\n",
    "\n",
    "#for h in id_FINAL:\n",
    "    #FINA = re.search(r'\\s.*?(?=$)', h, re.DOTALL)\n",
    "    #if FINA:\n",
    "        #print (FINA.group(0))\n",
    "        #lista_final_final.append([FINA.group(0)])\n",
    "    #else:\n",
    "        #lista_final_final.append([])\n",
    "\n",
    "#for i in lista_final_final:\n",
    "    #print (i)\n",
    "#SE=\",\".join(lista_final_final[0])\n",
    "#id_FI= SE.split(' ')\n",
    "#print(lista_final_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINAL\n",
    "#result_dict = {}\n",
    "#database = 'nucleotide'\n",
    "#email= 'rodrigoce9@gmail.com'\n",
    "#idlist=Ids\n",
    "# idlist= Ids.remove('U49845')\n",
    "#for ids in idlist:\n",
    "    #list_pro=[]\n",
    "    #handle = Entrez.efetch(db=database, id=ids, rettype=\"gb\") \n",
    "   #records = list(SeqIO.parse(handle,\"gb\"))\n",
    "    #handle.close()\n",
    "    #for info in records:\n",
    "        #list_pro.append(info.id)\n",
    "        #for i in info.features:\n",
    "            #if i.type == \"CDS\":\n",
    "                #pro= str(i.qualifiers[\"protein_id\"])\n",
    "                #list_pro.append(pro)\n",
    "        #if len(list_pro)==1: #if no protein_id was found\n",
    "            #result_dict[info.id] = \"N/A\"\n",
    "        #else:\n",
    "            #list_pro = [x.replace(\"['\",'').replace(\"']\",'') for x in list_pro]\n",
    "            #result_dict[info.id] = ', '.join(list_pro[1:])\n",
    "#print(result_dict)\n",
    "#key: id_genebank; values: id_Uniprot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buscar artigos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 3012462\n",
      "affiliation:  ['N/A']\n",
      "\n",
      "id: 14663149\n",
      "affiliation:  ['Laboratory for Genome Exploration Research Group, RIKEN Genomic Sciences Center, Yokohama Institute 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, Kanagawa 230-0045, Japan.']\n",
      "\n",
      "id: 14960301\n",
      "affiliation:  ['Genome Science Laboratory, RIKEN, Wako Main Campus, Hirosawa 2-1, Wako, Saitama 351-0198, Japan.']\n",
      "\n",
      "id: 16141072\n",
      "affiliation:  ['N/A']\n",
      "\n",
      "id: 16141073\n",
      "affiliation:  ['Laboratory for Genome Exploration Research Group, RIKEN Genomic Sciences Centre (GSC), RIKEN Yokohama Institute, 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, 230-0045, Japan.']\n",
      "\n",
      "id: 16645617\n",
      "affiliation:  ['Genome Exploration Research Group, RIKEN Genomic Sciences Center, RIKEN Yokohama Institute, 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, Kanagawa, 230-0045, Japan.']\n",
      "\n",
      "id: 8116255\n",
      "affiliation:  ['Laboratory of Central Nervous System Studies, National Institute of Neurological Disorders and Stroke, National Institutes of Health, Bethesda, Maryland 20892.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titles= []\n",
    "authors=[]\n",
    "source=[]\n",
    "affiliation=[]\n",
    "database = 'PubMed'\n",
    "email= 'rodrigoce9@gmail.com'\n",
    "idlist= new_list_\n",
    "counter = 0\n",
    "for i in idlist:\n",
    "    if i!= \"N/A\":\n",
    "        handle = Entrez.efetch(db=database, id=i, rettype=\"medline\", retmode=\"text\") \n",
    "        records = Medline.parse(handle)\n",
    "        for info in records:\n",
    "            print(f'id: {i}')\n",
    "            #print(\"title:\", info.get(\"TI\", \"-\"))\n",
    "            titles.append(info.get(\"TI\", \"-\"))\n",
    "            #print('authors: ', info.get(\"AU\", \"-\"))\n",
    "            authors_string = info.get(\"AU\", \"-\")\n",
    "            if len(authors_string) > 5:\n",
    "                authors_h = authors_string[0:5]\n",
    "                authors.append(authors_h)\n",
    "            else:\n",
    "                authors.append(authors_string) \n",
    "            #print(\"source:\", info.get(\"SO\", \"-\"))\n",
    "            #source.append(info.get((\"SO\", [\"N/A\"]))\n",
    "            print(\"affiliation: \", info.get(\"AD\", [\"N/A\"]) ) # FAZER O IF/ELSE PARA O CASO DE NÃO TER AFFILIATION\n",
    "            affiliation_string= info.get(\"AD\", [\"N/A\"])\n",
    "            if len(affiliation_string) > 5:\n",
    "                affiliation_h = affiliation_string[0:5]\n",
    "                affiliation.append(affiliation_h)\n",
    "            else:\n",
    "                affiliation.append(affiliation_string)\n",
    "            print()\n",
    "            counter += 1\n",
    "    else:\n",
    "        #print(f'id: {i} - N/A')\n",
    "        titles.append(\"N/A\")\n",
    "        authors.append([\"N/A\"])\n",
    "        source.append(\"N/A\")\n",
    "        affiliation.append([\"N/A\"])\n",
    "        #print()\n",
    "        counter += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### buscar titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [ [title] for title in titles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### buscar doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doi_list = []\n",
    "for x in source:\n",
    "    match = re.search(\"doi: (.*)\", x)\n",
    "    if match:\n",
    "        doi_list.append(match.group(1))\n",
    "    else:\n",
    "        doi_list.append(\"N/A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### buscar authors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_new = []\n",
    "for sub_list in authors:\n",
    "    for author in sub_list:\n",
    "        authors_new.append([author])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_authors_dict = {i: authors[counter] if i != \"N/A\" else [\"N/A\"] for counter, i in enumerate(idlist)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3012462': ['Leutwiler LS', 'Meyerowitz EM', 'Tobin EM'], 'N/A': ['N/A'], '14663149': ['Shiraki T', 'Kondo S', 'Katayama S', 'Waki K', 'Kasukawa T'], '14960301': ['Kodzius R', 'Matsumura Y', 'Kasukawa T', 'Shimokawa K', 'Fukuda S'], '16141072': ['Carninci P', 'Kasukawa T', 'Katayama S', 'Gough J', 'Frith MC'], '16141073': ['Katayama S', 'Tomaru Y', 'Kasukawa T', 'Waki K', 'Nakanishi M'], '16645617': ['Carninci P', 'Sandelin A', 'Lenhard B', 'Katayama S', 'Shimokawa K'], '8116255': ['Song KJ', 'Nerurkar VR', 'Saitou N', 'Lazo A', 'Blakeslee JR']}\n"
     ]
    }
   ],
   "source": [
    "print(id_authors_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pubmed_list = []\n",
    "authors_list = []\n",
    "for key, vals in id_authors_dict.items():\n",
    "    if vals:\n",
    "        for val in vals:\n",
    "            pubmed_list.append(key)\n",
    "            authors_list.append(val)\n",
    "    #else:\n",
    "        #pubmed_list.append(key)\n",
    "        #authors_list .append(\"N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3012462', '3012462', '3012462', 'N/A', '14663149', '14663149', '14663149', '14663149', '14663149', '14960301', '14960301', '14960301', '14960301', '14960301', '16141072', '16141072', '16141072', '16141072', '16141072', '16141073', '16141073', '16141073', '16141073', '16141073', '16645617', '16645617', '16645617', '16645617', '16645617', '8116255', '8116255', '8116255', '8116255', '8116255']\n"
     ]
    }
   ],
   "source": [
    "print(pubmed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Leutwiler LS', 'Meyerowitz EM', 'Tobin EM', 'N/A', 'Shiraki T', 'Kondo S', 'Katayama S', 'Waki K', 'Kasukawa T', 'Kodzius R', 'Matsumura Y', 'Kasukawa T', 'Shimokawa K', 'Fukuda S', 'Carninci P', 'Kasukawa T', 'Katayama S', 'Gough J', 'Frith MC', 'Katayama S', 'Tomaru Y', 'Kasukawa T', 'Waki K', 'Nakanishi M', 'Carninci P', 'Sandelin A', 'Lenhard B', 'Katayama S', 'Shimokawa K', 'Song KJ', 'Nerurkar VR', 'Saitou N', 'Lazo A', 'Blakeslee JR']\n"
     ]
    }
   ],
   "source": [
    "print(authors_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Leutwiler LS', 'Meyerowitz EM', 'Tobin EM', 'N/A', 'Shiraki T', 'Kondo S', 'Katayama S', 'Waki K', 'Kasukawa T', 'Kodzius R', 'Matsumura Y', 'Shimokawa K', 'Fukuda S', 'Carninci P', 'Gough J', 'Frith MC', 'Tomaru Y', 'Nakanishi M', 'Sandelin A', 'Lenhard B', 'Song KJ', 'Nerurkar VR', 'Saitou N', 'Lazo A', 'Blakeslee JR']\n"
     ]
    }
   ],
   "source": [
    "new_list_authors= []\n",
    "seen = set()\n",
    "for item in authors_list:\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        new_list_authors.append(item)\n",
    "print(new_list_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_map_pub = {}\n",
    "next_number = 1\n",
    "output_pub = []\n",
    "for number in pubmed_list:\n",
    "    if number not in number_map_pub:\n",
    "        number_map_pub[number] = next_number\n",
    "        next_number += 1\n",
    "    output_pub.append(number_map_pub[number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 3, 4, 5, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 9, 12, 13, 14, 9, 7, 15, 16, 7, 17, 9, 8, 18, 14, 19, 20, 7, 12, 21, 22, 23, 24, 25]\n"
     ]
    }
   ],
   "source": [
    "number_map_ = {}\n",
    "next_number = 1\n",
    "output_authors = []\n",
    "for number in authors_list:\n",
    "    if number not in number_map:\n",
    "        number_map_[number] = next_number\n",
    "        next_number += 1\n",
    "    output.append(number_map[number])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### buscar affil:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['N/A'], ['N/A'], ['Laboratory for Genome Exploration Research Group, RIKEN Genomic Sciences Center, Yokohama Institute 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, Kanagawa 230-0045, Japan.'], ['Genome Science Laboratory, RIKEN, Wako Main Campus, Hirosawa 2-1, Wako, Saitama 351-0198, Japan.'], ['N/A'], ['Laboratory for Genome Exploration Research Group, RIKEN Genomic Sciences Centre (GSC), RIKEN Yokohama Institute, 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, 230-0045, Japan.'], ['Genome Exploration Research Group, RIKEN Genomic Sciences Center, RIKEN Yokohama Institute, 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, Kanagawa, 230-0045, Japan.'], ['Laboratory of Central Nervous System Studies, National Institute of Neurological Disorders and Stroke, National Institutes of Health, Bethesda, Maryland 20892.']]\n"
     ]
    }
   ],
   "source": [
    "print(affiliation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N/A', 'N/A', 'Laboratory for Genome Exploration Research Group, RIKEN Genomic Sciences Center, Yokohama Institute 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, Kanagawa 230-0045, Japan.', 'Genome Science Laboratory, RIKEN, Wako Main Campus, Hirosawa 2-1, Wako, Saitama 351-0198, Japan.', 'N/A', 'Laboratory for Genome Exploration Research Group, RIKEN Genomic Sciences Centre (GSC), RIKEN Yokohama Institute, 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, 230-0045, Japan.', 'Genome Exploration Research Group, RIKEN Genomic Sciences Center, RIKEN Yokohama Institute, 1-7-22 Suehiro-cho, Tsurumi-ku, Yokohama, Kanagawa, 230-0045, Japan.', 'Laboratory of Central Nervous System Studies, National Institute of Neurological Disorders and Stroke, National Institutes of Health, Bethesda, Maryland 20892.']\n"
     ]
    }
   ],
   "source": [
    "single_affiliation_list = []\n",
    "for i in affiliation:\n",
    "    single_affiliation_list.extend(i)\n",
    "\n",
    "print(single_affiliation_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "affiliation_new = []\n",
    "for sub_list in affiliation:\n",
    "    for affiliation in sub_list:\n",
    "        affiliation_new.append([affiliation])\n",
    "#print(affiliation_new)\n",
    "\n",
    "id_affiliation_dict = {i: [single_affiliation_list[counter]] if i != \"N/A\" else [\"N/A\"] for counter, i in enumerate(idlist)}\n",
    "\n",
    "pubmed_affi_list = []\n",
    "affi_list = []\n",
    "for key, vals in id_affiliation_dict.items():\n",
    "    if vals:\n",
    "        for val in vals:\n",
    "            pubmed_affi_list.append(key)\n",
    "            affi_list.append(val)\n",
    "    else:\n",
    "        pubmed_affi_list.append(key)\n",
    "        affi_list.append([\"N/A\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list_affi= []\n",
    "seen = set()\n",
    "for item in single_affiliation_list :\n",
    "    if item not in seen:\n",
    "        seen.add(item)\n",
    "        new_list_affi.append(item)\n",
    "\n",
    "number_map_affi_pub = {}\n",
    "next_number = int(SEARCH_ID_[0])\n",
    "output_pub_affi = []\n",
    "for number in pubmed_affi_listt:\n",
    "    if number not in number_map_affi:\n",
    "        number_map_affi[number] = next_number\n",
    "        next_number += 1\n",
    "    output_pub_affi.append(number_map_affi[number])\n",
    "    \n",
    "number_map_affi = {}\n",
    "next_number = 1\n",
    "output_affi = []\n",
    "for number in affi_list:\n",
    "    if number not in number_map_affi:\n",
    "        number_map_affi[number] = next_number\n",
    "        next_number += 1\n",
    "    output_affi.append(number_map_affi[number])\n"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "Jorge Gustavo Rocha"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
